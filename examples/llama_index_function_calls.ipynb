{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-index-agent-openai\n",
    "# %pip install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_index.core\n",
    "\n",
    "from tracing_auto_instrumentation.llama_index import LlamaIndexCallbackHandler\n",
    "llama_index.core.global_handler = LlamaIndexCallbackHandler(\n",
    "    project_name=\"Function call demo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key configured\n"
     ]
    }
   ],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.tools import BaseTool, FunctionTool\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "from getpass import getpass\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\n",
    "        \"Paste your OpenAI key from:\"\n",
    "        \" https://platform.openai.com/account/api-keys\\n\"\n",
    "    )\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\n",
    "    \"sk-\"\n",
    "), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-1106\")\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [multiply_tool, add_tool], llm=llm, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG] 2024-06-11 20:20:34,727 _config.py:80: load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "[DEBUG] 2024-06-11 20:20:34,728 _config.py:146: load_verify_locations cafile='/opt/homebrew/Caskroom/miniconda/base/envs/eval/lib/python3.12/site-packages/certifi/cacert.pem'\n",
      "[DEBUG] 2024-06-11 20:20:34,735 _base_client.py:446: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is (121 * 3) + 42?'}], 'model': 'gpt-3.5-turbo-1106', 'stream': False, 'temperature': 0.1, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "[DEBUG] 2024-06-11 20:20:34,754 _base_client.py:949: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "[DEBUG] 2024-06-11 20:20:34,758 _trace.py:45: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "[DEBUG] 2024-06-11 20:20:34,803 _trace.py:45: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x3361d6e70>\n",
      "[DEBUG] 2024-06-11 20:20:34,803 _trace.py:45: start_tls.started ssl_context=<ssl.SSLContext object at 0x3351bb8d0> server_hostname='api.openai.com' timeout=60.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is (121 * 3) + 42?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG] 2024-06-11 20:20:34,819 _trace.py:45: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x334cdeea0>\n",
      "[DEBUG] 2024-06-11 20:20:34,819 _trace.py:45: send_request_headers.started request=<Request [b'POST']>\n",
      "[DEBUG] 2024-06-11 20:20:34,820 _trace.py:45: send_request_headers.complete\n",
      "[DEBUG] 2024-06-11 20:20:34,820 _trace.py:45: send_request_body.started request=<Request [b'POST']>\n",
      "[DEBUG] 2024-06-11 20:20:34,820 _trace.py:45: send_request_body.complete\n",
      "[DEBUG] 2024-06-11 20:20:34,820 _trace.py:45: receive_response_headers.started request=<Request [b'POST']>\n",
      "[DEBUG] 2024-06-11 20:20:36,122 _trace.py:45: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 12 Jun 2024 00:20:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'lastmile-ai'), (b'openai-processing-ms', b'848'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999977'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_b43f5839bfbcde690c664a03c1e3014c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dS2H_eoU7Y3J_5.mmJOe4rpdFqpB5nU1m.GEjDyUNFk-1718151636-1.0.1.1-SlKpQbEnG3aWFb0SDPwnoa42I2HCOzzHkwt56OQHSCs5LPsnSroGmFoBSb936aB37LIzrp.adP8I6WAtqoKWhQ; path=/; expires=Wed, 12-Jun-24 00:50:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=PjywuXMuXI1JPBknC8ryBObUJ3BDu2mB7a77E0tzduk-1718151636036-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8925ad05dfd072b7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "[INFO] 2024-06-11 20:20:36,123 _client.py:1026: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[DEBUG] 2024-06-11 20:20:36,124 _trace.py:45: receive_response_body.started request=<Request [b'POST']>\n",
      "[DEBUG] 2024-06-11 20:20:36,125 _trace.py:45: receive_response_body.complete\n",
      "[DEBUG] 2024-06-11 20:20:36,125 _trace.py:45: response_closed.started\n",
      "[DEBUG] 2024-06-11 20:20:36,125 _trace.py:45: response_closed.complete\n",
      "[DEBUG] 2024-06-11 20:20:36,125 _base_client.py:988: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Wed, 12 Jun 2024 00:20:36 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('openai-organization', 'lastmile-ai'), ('openai-processing-ms', '848'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=15724800; includeSubDomains'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '2000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '1999977'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '0s'), ('x-request-id', 'req_b43f5839bfbcde690c664a03c1e3014c'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=dS2H_eoU7Y3J_5.mmJOe4rpdFqpB5nU1m.GEjDyUNFk-1718151636-1.0.1.1-SlKpQbEnG3aWFb0SDPwnoa42I2HCOzzHkwt56OQHSCs5LPsnSroGmFoBSb936aB37LIzrp.adP8I6WAtqoKWhQ; path=/; expires=Wed, 12-Jun-24 00:50:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('set-cookie', '_cfuvid=PjywuXMuXI1JPBknC8ryBObUJ3BDu2mB7a77E0tzduk-1718151636036-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8925ad05dfd072b7-EWR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "[DEBUG] 2024-06-11 20:20:36,126 _base_client.py:996: request_id: req_b43f5839bfbcde690c664a03c1e3014c\n",
      "[ERROR] 2024-06-11 20:20:36,129 llama_index_callback_handler.py:381: Failed to set attributes on span. event_type=CBEventType.LLM, attributes={'llm.input_messages': [{'message.role': 'user', 'message.content': 'What is (121 * 3) + 42?'}], 'llm.model_name': 'gpt-3.5-turbo-1106', 'llm.invocation_parameters': '{\"temperature\": 0.1, \"model\": \"gpt-3.5-turbo-1106\"}', 'output.value': '{\"tool_calls\": [\"ChatCompletionMessageToolCall(id=\\'call_dGdgo8IEntW1dAR8unEFCSVK\\', function=Function(arguments=\\'{\\\\\"a\\\\\": 121, \\\\\"b\\\\\": 3}\\', name=\\'multiply\\'), type=\\'function\\')\", \"ChatCompletionMessageToolCall(id=\\'call_FgbAaKMi3HtGZxZwzEsjDOfN\\', function=Function(arguments=\\'{\\\\\"a\\\\\": 363, \\\\\"b\\\\\": 42}\\', name=\\'add\\'), type=\\'function\\')\"]}', 'output.mime_type': 'application/json', 'llm.output_messages': [{'message.role': 'assistant', 'message.tool_calls': [{'tool_call.function.name': 'multiply', 'tool_call.function.arguments': '{\"a\": 121, \"b\": 3}'}, {'tool_call.function.name': 'add', 'tool_call.function.arguments': '{\"a\": 363, \"b\": 42}'}]}], 'llm.token_count.prompt': 129, 'llm.token_count.completion': 49, 'llm.token_count.total': 178}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rossdancraig/Projects/tracing_auto_instrumentation/src/tracing_auto_instrumentation/llama_index/llama_index_callback_handler.py\", line 322, in _finish_tracing\n",
      "    template: str = serializable_payload[LLM_PROMPT_TEMPLATE]\n",
      "                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'llm.prompt_template.template'\n",
      "[DEBUG] 2024-06-11 20:20:36,132 connectionpool.py:1055: Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "[DEBUG] 2024-06-11 20:20:36,300 connectionpool.py:549: https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "[DEBUG] 2024-06-11 20:20:36,340 connectionpool.py:549: https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "[DEBUG] 2024-06-11 20:20:36,374 connectionpool.py:549: https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "[DEBUG] 2024-06-11 20:20:36,379 _base_client.py:446: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is (121 * 3) + 42?'}, {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_dGdgo8IEntW1dAR8unEFCSVK', 'function': {'arguments': '{\"a\": 121, \"b\": 3}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_FgbAaKMi3HtGZxZwzEsjDOfN', 'function': {'arguments': '{\"a\": 363, \"b\": 42}', 'name': 'add'}, 'type': 'function'}]}, {'role': 'tool', 'content': '363', 'name': 'multiply', 'tool_call_id': 'call_dGdgo8IEntW1dAR8unEFCSVK'}, {'role': 'tool', 'content': '405', 'name': 'add', 'tool_call_id': 'call_FgbAaKMi3HtGZxZwzEsjDOfN'}], 'model': 'gpt-3.5-turbo-1106', 'stream': False, 'temperature': 0.1, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "[DEBUG] 2024-06-11 20:20:36,379 _base_client.py:949: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "[DEBUG] 2024-06-11 20:20:36,380 _trace.py:45: send_request_headers.started request=<Request [b'POST']>\n",
      "[DEBUG] 2024-06-11 20:20:36,380 _trace.py:45: send_request_headers.complete\n",
      "[DEBUG] 2024-06-11 20:20:36,380 _trace.py:45: send_request_body.started request=<Request [b'POST']>\n",
      "[DEBUG] 2024-06-11 20:20:36,381 _trace.py:45: send_request_body.complete\n",
      "[DEBUG] 2024-06-11 20:20:36,381 _trace.py:45: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\"a\": 121, \"b\": 3}\n",
      "Got output: 363\n",
      "========================\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: add with args: {\"a\": 363, \"b\": 42}\n",
      "Got output: 405\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG] 2024-06-11 20:20:37,249 _trace.py:45: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 12 Jun 2024 00:20:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'lastmile-ai'), (b'openai-processing-ms', b'502'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999971'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_4798b47c9a4331c8dc0a65d9ad323f2c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8925ad0f9a2572b7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "[INFO] 2024-06-11 20:20:37,251 _client.py:1026: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[DEBUG] 2024-06-11 20:20:37,251 _trace.py:45: receive_response_body.started request=<Request [b'POST']>\n",
      "[DEBUG] 2024-06-11 20:20:37,252 _trace.py:45: receive_response_body.complete\n",
      "[DEBUG] 2024-06-11 20:20:37,252 _trace.py:45: response_closed.started\n",
      "[DEBUG] 2024-06-11 20:20:37,253 _trace.py:45: response_closed.complete\n",
      "[DEBUG] 2024-06-11 20:20:37,254 _base_client.py:988: HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 12 Jun 2024 00:20:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'lastmile-ai', 'openai-processing-ms': '502', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999971', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_4798b47c9a4331c8dc0a65d9ad323f2c', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8925ad0f9a2572b7-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "[DEBUG] 2024-06-11 20:20:37,254 _base_client.py:996: request_id: req_4798b47c9a4331c8dc0a65d9ad323f2c\n",
      "[ERROR] 2024-06-11 20:20:37,256 llama_index_callback_handler.py:381: Failed to set attributes on span. event_type=CBEventType.LLM, attributes={'llm.input_messages': [{'message.role': 'user', 'message.content': 'What is (121 * 3) + 42?'}, {'message.role': 'assistant', 'message.content': None, 'message.tool_calls': [{'tool_call.function.name': 'multiply', 'tool_call.function.arguments': '{\"a\": 121, \"b\": 3}'}, {'tool_call.function.name': 'add', 'tool_call.function.arguments': '{\"a\": 363, \"b\": 42}'}]}, {'message.role': 'tool', 'message.content': '363', 'message.name': 'multiply'}, {'message.role': 'tool', 'message.content': '405', 'message.name': 'add'}], 'llm.model_name': 'gpt-3.5-turbo-1106', 'llm.invocation_parameters': '{\"temperature\": 0.1, \"model\": \"gpt-3.5-turbo-1106\"}', 'output.value': 'The result of (121 * 3) is 363, and when you add 42 to it, you get 405.', 'llm.output_messages': [{'message.role': 'assistant', 'message.content': 'The result of (121 * 3) is 363, and when you add 42 to it, you get 405.'}], 'llm.token_count.prompt': 194, 'llm.token_count.completion': 28, 'llm.token_count.total': 222}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rossdancraig/Projects/tracing_auto_instrumentation/src/tracing_auto_instrumentation/llama_index/llama_index_callback_handler.py\", line 322, in _finish_tracing\n",
      "    template: str = serializable_payload[LLM_PROMPT_TEMPLATE]\n",
      "                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'llm.prompt_template.template'\n",
      "[DEBUG] 2024-06-11 20:20:37,290 connectionpool.py:549: https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "[DEBUG] 2024-06-11 20:20:37,332 connectionpool.py:549: https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "[DEBUG] 2024-06-11 20:20:37,335 connectionpool.py:1055: Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "[DEBUG] 2024-06-11 20:20:37,418 connectionpool.py:549: https://lastmileai.dev:443 \"POST /api/rag_query_traces/create HTTP/1.1\" 200 645\n",
      "[DEBUG] 2024-06-11 20:20:37,422 connectionpool.py:1055: Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "[DEBUG] 2024-06-11 20:20:37,504 connectionpool.py:549: https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 482\n",
      "[DEBUG] 2024-06-11 20:20:37,507 connectionpool.py:1055: Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "[DEBUG] 2024-06-11 20:20:37,585 connectionpool.py:549: https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 477\n",
      "[DEBUG] 2024-06-11 20:20:37,590 connectionpool.py:1055: Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "[DEBUG] 2024-06-11 20:20:37,785 connectionpool.py:549: https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of (121 * 3) is 363, and when you add 42 to it, you get 405.\n"
     ]
    }
   ],
   "source": [
    "# Note: if you have a APIConnectionError and are on a Mac Silicon device,\n",
    "# you may need to run the following command in your terminal:\n",
    "# bash /Applications/Python*/Install\\ Certificates.command\n",
    "\n",
    "# After running the command above, please restart this notebook and try again\n",
    "\n",
    "response = agent.chat(\"What is (121 * 3) + 42?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
