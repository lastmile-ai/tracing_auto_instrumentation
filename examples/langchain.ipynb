{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan-and-Execute with LastMile Auto Instrumentation\n",
    "\n",
    "This notebook demonstrates the concept of a \"Plan-and-Execute\" LangChain agent with LastMile auto instrumentation. The agent accomplishes an objective by first planning what to do and then executing the sub-tasks. LastMile auto instrumentation is used to trace and monitor the execution of the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.2.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.30-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.9.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_core-0.2.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.60-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Using cached pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Downloading requests-2.32.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.3-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic<3,>=1->langchain)\n",
      "  Using cached pydantic_core-2.18.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Collecting typing-extensions>=4.6.1 (from pydantic<3,>=1->langchain)\n",
      "  Using cached typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain)\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain-0.2.0-py3-none-any.whl (973 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached aiohttp-3.9.5-cp310-cp310-macosx_11_0_arm64.whl (389 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_core-0.2.1-py3-none-any.whl (308 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.5/308.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
      "Downloading langsmith-0.1.60-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Using cached pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "Using cached pydantic_core-2.18.2-cp310-cp310-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached PyYAML-6.0.1-cp310-cp310-macosx_11_0_arm64.whl (169 kB)\n",
      "Downloading requests-2.32.2-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached SQLAlchemy-2.0.30-cp310-cp310-macosx_11_0_arm64.whl (2.1 MB)\n",
      "Downloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp310-cp310-macosx_11_0_arm64.whl (120 kB)\n",
      "Using cached frozenlist-1.4.1-cp310-cp310-macosx_11_0_arm64.whl (52 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "Using cached multidict-6.0.5-cp310-cp310-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached orjson-3.10.3-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (253 kB)\n",
      "Using cached typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Using cached yarl-1.9.4-cp310-cp310-macosx_11_0_arm64.whl (79 kB)\n",
      "Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tenacity, PyYAML, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpointer, idna, frozenlist, charset-normalizer, certifi, attrs, async-timeout, annotated-types, yarl, typing-inspect, SQLAlchemy, requests, pydantic-core, jsonpatch, aiosignal, pydantic, dataclasses-json, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.30 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.7.0 async-timeout-4.0.3 attrs-23.2.0 certifi-2024.2.2 charset-normalizer-3.3.2 dataclasses-json-0.6.6 frozenlist-1.4.1 idna-3.7 jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.0 langchain-core-0.2.1 langchain-text-splitters-0.2.0 langsmith-0.1.60 marshmallow-3.21.2 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.10.3 pydantic-2.7.1 pydantic-core-2.18.2 requests-2.32.2 tenacity-8.3.0 typing-extensions-4.11.0 typing-inspect-0.9.0 urllib3-2.2.1 yarl-1.9.4\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.2.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_community) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_community) (0.6.6)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_community) (0.2.0)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_community) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_community) (0.1.60)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_community) (2.32.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_community) (8.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (0.2.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (2.7.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.11.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (2.18.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain_community\n",
      "Successfully installed langchain_community-0.2.0\n",
      "Requirement already satisfied: langchain_core in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_core) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_core) (0.1.60)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_core) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_core) (2.7.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_core) (8.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_core) (3.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_core) (2.32.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from pydantic<3,>=1->langchain_core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from pydantic<3,>=1->langchain_core) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from pydantic<3,>=1->langchain_core) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain_core) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain_core) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain_core) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain_core) (2024.2.2)\n",
      "Collecting langchain_experimental\n",
      "  Downloading langchain_experimental-0.0.59-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: langchain-community<0.3,>=0.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_experimental) (0.2.0)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_experimental) (0.2.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (0.6.6)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (0.2.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (0.1.60)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (2.32.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (8.3.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2->langchain_experimental) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2->langchain_experimental) (2.7.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3,>=0.2->langchain_experimental) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3,>=0.2->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2->langchain_experimental) (2.4)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.0->langchain-community<0.3,>=0.2->langchain_experimental) (0.2.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community<0.3,>=0.2->langchain_experimental) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langchain_experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langchain_experimental) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langchain_experimental) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests<3,>=2->langchain-community<0.3,>=0.2->langchain_experimental) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests<3,>=2->langchain-community<0.3,>=0.2->langchain_experimental) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests<3,>=2->langchain-community<0.3,>=0.2->langchain_experimental) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests<3,>=2->langchain-community<0.3,>=0.2->langchain_experimental) (2024.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3,>=0.2->langchain_experimental) (1.0.0)\n",
      "Downloading langchain_experimental-0.0.59-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain_experimental\n",
      "Successfully installed langchain_experimental-0.0.59\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.46 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain_openai) (0.2.1)\n",
      "Collecting openai<2.0.0,>=1.24.0 (from langchain_openai)\n",
      "  Downloading openai-1.30.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (0.1.60)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (2.7.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (8.3.0)\n",
      "Collecting anyio<5,>=3.5.0 (from openai<2.0.0,>=1.24.0->langchain_openai)\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.24.0->langchain_openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.24.0->langchain_openai)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting sniffio (from openai<2.0.0,>=1.24.0->langchain_openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.24.0->langchain_openai)\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.11.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain_openai)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain_openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.46->langchain_openai) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain_openai) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.1)\n",
      "Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
      "Downloading openai-1.30.1-py3-none-any.whl (320 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-macosx_11_0_arm64.whl (906 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.8/906.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Downloading regex-2024.5.15-cp310-cp310-macosx_11_0_arm64.whl (278 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.3/278.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: tqdm, sniffio, regex, h11, distro, tiktoken, httpcore, anyio, httpx, openai, langchain_openai\n",
      "Successfully installed anyio-4.3.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 langchain_openai-0.1.7 openai-1.30.1 regex-2024.5.15 sniffio-1.3.1 tiktoken-0.7.0 tqdm-4.66.4\n",
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4 (from wikipedia)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from wikipedia) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->wikipedia)\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=f2a72788141cf423796bd453269261af8996f04e6f2e4e191e53009cd9912b23\n",
      "  Stored in directory: /Users/jonathan/Library/Caches/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: soupsieve, beautifulsoup4, wikipedia\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.5 wikipedia-1.4.0\n",
      "Collecting numexpr\n",
      "  Downloading numexpr-2.10.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from numexpr) (1.26.4)\n",
      "Downloading numexpr-2.10.0-cp310-cp310-macosx_11_0_arm64.whl (92 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numexpr\n",
      "Successfully installed numexpr-2.10.0\n",
      "Collecting lastmile_eval\n",
      "  Downloading lastmile_eval-0.0.44-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting dataclasses (from lastmile_eval)\n",
      "  Using cached dataclasses-0.6-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from lastmile_eval) (2.32.2)\n",
      "Collecting python-dotenv (from lastmile_eval)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting rouge-score (from lastmile_eval)\n",
      "  Using cached rouge_score-0.1.2-py3-none-any.whl\n",
      "Collecting nltk (from lastmile_eval)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: openai>=1.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from lastmile_eval) (1.30.1)\n",
      "Collecting python-aiconfig (from lastmile_eval)\n",
      "  Using cached python_aiconfig-1.1.34-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: pydantic>=2.1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from lastmile_eval) (2.7.1)\n",
      "Collecting anthropic (from lastmile_eval)\n",
      "  Downloading anthropic-0.26.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting evaluate==0.4.1 (from lastmile_eval)\n",
      "  Using cached evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting arize-phoenix-evals==0.5.0 (from lastmile_eval)\n",
      "  Using cached arize_phoenix_evals-0.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting pandas==2.1.2 (from lastmile_eval)\n",
      "  Using cached pandas-2.1.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting instructor (from lastmile_eval)\n",
      "  Downloading instructor-1.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting opentelemetry-api (from lastmile_eval)\n",
      "  Using cached opentelemetry_api-1.24.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting opentelemetry-sdk (from lastmile_eval)\n",
      "  Using cached opentelemetry_sdk-1.24.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp (from lastmile_eval)\n",
      "  Using cached opentelemetry_exporter_otlp-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-semantic-conventions (from lastmile_eval)\n",
      "  Using cached opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting openinference-semantic-conventions (from lastmile_eval)\n",
      "  Using cached openinference_semantic_conventions-0.1.6-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting fastapi==0.110.1 (from lastmile_eval)\n",
      "  Using cached fastapi-0.110.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting jinja2 (from lastmile_eval)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting uvicorn (from lastmile_eval)\n",
      "  Using cached uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting result (from lastmile_eval)\n",
      "  Using cached result-0.16.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting lastmile-utils (from lastmile_eval)\n",
      "  Using cached lastmile_utils-0.0.24-py3-none-any.whl.metadata (869 bytes)\n",
      "Collecting email-validator==2.1.1 (from lastmile_eval)\n",
      "  Using cached email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting llama-index (from lastmile_eval)\n",
      "  Downloading llama_index-0.10.37-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-embeddings-openai (from lastmile_eval)\n",
      "  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl.metadata (604 bytes)\n",
      "Collecting llama-index-readers-web (from lastmile_eval)\n",
      "  Downloading llama_index_readers_web-0.1.16-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-index-callbacks-openinference (from lastmile_eval)\n",
      "  Using cached llama_index_callbacks_openinference-0.1.4-py3-none-any.whl.metadata (672 bytes)\n",
      "Collecting html2text (from lastmile_eval)\n",
      "  Using cached html2text-2024.2.26.tar.gz (56 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyarrow (from lastmile_eval)\n",
      "  Downloading pyarrow-16.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from lastmile_eval) (4.66.4)\n",
      "Collecting openinference-instrumentation-llama-index (from lastmile_eval)\n",
      "  Downloading openinference_instrumentation_llama_index-1.4.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting openinference-instrumentation-langchain (from lastmile_eval)\n",
      "  Downloading openinference_instrumentation_langchain-0.1.16-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: langchain in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from lastmile_eval) (0.2.0)\n",
      "Requirement already satisfied: langchain-core in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from lastmile_eval) (0.2.1)\n",
      "Requirement already satisfied: langchain-openai in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from lastmile_eval) (0.1.7)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from arize-phoenix-evals==0.5.0->lastmile_eval) (4.11.0)\n",
      "Collecting dnspython>=2.0.0 (from email-validator==2.1.1->lastmile_eval)\n",
      "  Using cached dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: idna>=2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from email-validator==2.1.1->lastmile_eval) (3.7)\n",
      "Collecting datasets>=2.0.0 (from evaluate==0.4.1->lastmile_eval)\n",
      "  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from evaluate==0.4.1->lastmile_eval) (1.26.4)\n",
      "Collecting dill (from evaluate==0.4.1->lastmile_eval)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from evaluate==0.4.1->lastmile_eval)\n",
      "  Using cached xxhash-3.4.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from evaluate==0.4.1->lastmile_eval)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate==0.4.1->lastmile_eval)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub>=0.7.0 (from evaluate==0.4.1->lastmile_eval)\n",
      "  Downloading huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from evaluate==0.4.1->lastmile_eval) (23.2)\n",
      "Collecting responses<0.19 (from evaluate==0.4.1->lastmile_eval)\n",
      "  Using cached responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi==0.110.1->lastmile_eval)\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from pandas==2.1.2->lastmile_eval) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas==2.1.2->lastmile_eval)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas==2.1.2->lastmile_eval)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from openai>=1.0.0->lastmile_eval) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from openai>=1.0.0->lastmile_eval) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from openai>=1.0.0->lastmile_eval) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from openai>=1.0.0->lastmile_eval) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from pydantic>=2.1->lastmile_eval) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from pydantic>=2.1->lastmile_eval) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests->lastmile_eval) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests->lastmile_eval) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from requests->lastmile_eval) (2024.2.2)\n",
      "Collecting jiter<1,>=0.1.0 (from anthropic->lastmile_eval)\n",
      "  Downloading jiter-0.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (1.4 kB)\n",
      "Collecting tokenizers>=0.13.0 (from anthropic->lastmile_eval)\n",
      "  Using cached tokenizers-0.19.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from instructor->lastmile_eval) (3.9.5)\n",
      "Collecting docstring-parser<0.17,>=0.16 (from instructor->lastmile_eval)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rich<14.0.0,>=13.7.0 (from instructor->lastmile_eval)\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from instructor->lastmile_eval) (8.3.0)\n",
      "Collecting typer<1.0.0,>=0.9.0 (from instructor->lastmile_eval)\n",
      "  Using cached typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->lastmile_eval)\n",
      "  Using cached MarkupSafe-2.1.5-cp310-cp310-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain->lastmile_eval) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain->lastmile_eval) (2.0.30)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain->lastmile_eval) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain->lastmile_eval) (0.6.6)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain->lastmile_eval) (0.2.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain->lastmile_eval) (0.1.60)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-core->lastmile_eval) (1.33)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langchain-openai->lastmile_eval) (0.7.0)\n",
      "Collecting black==23.11.0 (from lastmile-utils->lastmile_eval)\n",
      "  Using cached black-23.11.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (66 kB)\n",
      "Collecting chardet==5.2.0 (from lastmile-utils->lastmile_eval)\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting flake8==6.1.0 (from lastmile-utils->lastmile_eval)\n",
      "  Using cached flake8-6.1.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting isort==5.12.0 (from lastmile-utils->lastmile_eval)\n",
      "  Using cached isort-5.12.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pylint==3.0.2 (from lastmile-utils->lastmile_eval)\n",
      "  Using cached pylint-3.0.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pyright==1.1.335 (from lastmile-utils->lastmile_eval)\n",
      "  Using cached pyright-1.1.335-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting pytest==7.4.3 (from lastmile-utils->lastmile_eval)\n",
      "  Using cached pytest-7.4.3-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting python-dotenv (from lastmile_eval)\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting result (from lastmile_eval)\n",
      "  Using cached result-0.16.0-py3-none-any.whl.metadata (857 bytes)\n",
      "Collecting autoflake==2.2.1 (from lastmile-utils->lastmile_eval)\n",
      "  Using cached autoflake-2.2.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting pyflakes>=3.0.0 (from autoflake==2.2.1->lastmile-utils->lastmile_eval)\n",
      "  Using cached pyflakes-3.2.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting tomli>=2.0.1 (from autoflake==2.2.1->lastmile-utils->lastmile_eval)\n",
      "  Using cached tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting click>=8.0.0 (from black==23.11.0->lastmile-utils->lastmile_eval)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from black==23.11.0->lastmile-utils->lastmile_eval) (1.0.0)\n",
      "Collecting pathspec>=0.9.0 (from black==23.11.0->lastmile-utils->lastmile_eval)\n",
      "  Using cached pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from black==23.11.0->lastmile-utils->lastmile_eval) (3.10.0)\n",
      "Collecting mccabe<0.8.0,>=0.7.0 (from flake8==6.1.0->lastmile-utils->lastmile_eval)\n",
      "  Using cached mccabe-0.7.0-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pycodestyle<2.12.0,>=2.11.0 (from flake8==6.1.0->lastmile-utils->lastmile_eval)\n",
      "  Using cached pycodestyle-2.11.1-py2.py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting pyflakes>=3.0.0 (from autoflake==2.2.1->lastmile-utils->lastmile_eval)\n",
      "  Using cached pyflakes-3.1.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting astroid<=3.1.0-dev0,>=3.0.1 (from pylint==3.0.2->lastmile-utils->lastmile_eval)\n",
      "  Using cached astroid-3.0.3-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting tomlkit>=0.10.1 (from pylint==3.0.2->lastmile-utils->lastmile_eval)\n",
      "  Downloading tomlkit-0.12.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting nodeenv>=1.6.0 (from pyright==1.1.335->lastmile-utils->lastmile_eval)\n",
      "  Using cached nodeenv-1.8.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting iniconfig (from pytest==7.4.3->lastmile-utils->lastmile_eval)\n",
      "  Using cached iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pluggy<2.0,>=0.12 (from pytest==7.4.3->lastmile-utils->lastmile_eval)\n",
      "  Using cached pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from pytest==7.4.3->lastmile-utils->lastmile_eval) (1.2.0)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index->lastmile_eval)\n",
      "  Downloading llama_index_agent_openai-0.2.5-py3-none-any.whl.metadata (678 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index->lastmile_eval)\n",
      "  Using cached llama_index_cli-0.1.12-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.35 (from llama-index->lastmile_eval)\n",
      "  Downloading llama_index_core-0.10.37.post1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index->lastmile_eval)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index->lastmile_eval)\n",
      "  Using cached llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index->lastmile_eval)\n",
      "  Downloading llama_index_llms_openai-0.1.20-py3-none-any.whl.metadata (559 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index->lastmile_eval)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl.metadata (677 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index->lastmile_eval)\n",
      "  Using cached llama_index_program_openai-0.1.6-py3-none-any.whl.metadata (715 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index->lastmile_eval)\n",
      "  Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index->lastmile_eval)\n",
      "  Using cached llama_index_readers_file-0.1.22-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index->lastmile_eval)\n",
      "  Using cached llama_index_readers_llama_parse-0.1.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from llama-index-readers-web->lastmile_eval) (4.12.3)\n",
      "Collecting chromedriver-autoinstaller<0.7.0,>=0.6.3 (from llama-index-readers-web->lastmile_eval)\n",
      "  Using cached chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting html2text (from lastmile_eval)\n",
      "  Using cached html2text-2020.1.16-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting newspaper3k<0.3.0,>=0.2.8 (from llama-index-readers-web->lastmile_eval)\n",
      "  Using cached newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting playwright<2.0,>=1.30 (from llama-index-readers-web->lastmile_eval)\n",
      "  Downloading playwright-1.44.0-py3-none-macosx_11_0_arm64.whl.metadata (3.5 kB)\n",
      "Collecting selenium<5.0.0,>=4.17.2 (from llama-index-readers-web->lastmile_eval)\n",
      "  Downloading selenium-4.21.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting spider-client<0.0.12,>=0.0.11 (from llama-index-readers-web->lastmile_eval)\n",
      "  Using cached spider_client-0.0.11-py3-none-any.whl\n",
      "Collecting joblib (from nltk->lastmile_eval)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from nltk->lastmile_eval) (2024.5.15)\n",
      "Collecting openinference-instrumentation>=0.1.7 (from openinference-instrumentation-langchain->lastmile_eval)\n",
      "  Downloading openinference_instrumentation-0.1.7-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation (from openinference-instrumentation-langchain->lastmile_eval)\n",
      "  Using cached opentelemetry_instrumentation-0.45b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting wrapt (from openinference-instrumentation-langchain->lastmile_eval)\n",
      "  Using cached wrapt-1.16.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api->lastmile_eval)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api->lastmile_eval)\n",
      "  Using cached importlib_metadata-7.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc==1.24.0 (from opentelemetry-exporter-otlp->lastmile_eval)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http==1.24.0 (from opentelemetry-exporter-otlp->lastmile_eval)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.24.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->lastmile_eval)\n",
      "  Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting grpcio<2.0.0,>=1.0.0 (from opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->lastmile_eval)\n",
      "  Downloading grpcio-1.64.0-cp310-cp310-macosx_12_0_universal2.whl.metadata (3.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->lastmile_eval)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->lastmile_eval)\n",
      "  Using cached opentelemetry_proto-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf<5.0,>=3.19 (from opentelemetry-proto==1.24.0->opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->lastmile_eval)\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting anthropic-bedrock (from python-aiconfig->lastmile_eval)\n",
      "  Using cached anthropic_bedrock-0.8.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting flask-cors (from python-aiconfig->lastmile_eval)\n",
      "  Using cached Flask_Cors-4.0.1-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting flask[async] (from python-aiconfig->lastmile_eval)\n",
      "  Using cached flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting frozendict (from python-aiconfig->lastmile_eval)\n",
      "  Using cached frozendict-2.4.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (23 kB)\n",
      "Collecting google-generativeai>=0.3.1 (from python-aiconfig->lastmile_eval)\n",
      "  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting huggingface-hub>=0.7.0 (from evaluate==0.4.1->lastmile_eval)\n",
      "  Using cached huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting hypothesis==6.91.0 (from python-aiconfig->lastmile_eval)\n",
      "  Using cached hypothesis-6.91.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: nest-asyncio in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from python-aiconfig->lastmile_eval) (1.6.0)\n",
      "Requirement already satisfied: prompt-toolkit in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from python-aiconfig->lastmile_eval) (3.0.43)\n",
      "Collecting pybars3 (from python-aiconfig->lastmile_eval)\n",
      "  Using cached pybars3-0.9.7-py3-none-any.whl\n",
      "Collecting ruamel.yaml (from python-aiconfig->lastmile_eval)\n",
      "  Using cached ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from hypothesis==6.91.0->python-aiconfig->lastmile_eval) (23.2.0)\n",
      "Collecting sortedcontainers<3.0.0,>=2.1.0 (from hypothesis==6.91.0->python-aiconfig->lastmile_eval)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting absl-py (from rouge-score->lastmile_eval)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from rouge-score->lastmile_eval) (1.16.0)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from uvicorn->lastmile_eval) (0.14.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->lastmile_eval) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->lastmile_eval) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->lastmile_eval) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor->lastmile_eval) (1.9.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-web->lastmile_eval) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->lastmile_eval) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->lastmile_eval) (0.9.0)\n",
      "Collecting filelock (from datasets>=2.0.0->evaluate==0.4.1->lastmile_eval)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting pyarrow-hotfix (from datasets>=2.0.0->evaluate==0.4.1->lastmile_eval)\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate==0.4.1->lastmile_eval)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.4 (from google-generativeai>=0.3.1->python-aiconfig->lastmile_eval)\n",
      "  Downloading google_ai_generativelanguage-0.6.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google-generativeai>=0.3.1->python-aiconfig->lastmile_eval)\n",
      "  Using cached google_api_core-2.19.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-api-python-client (from google-generativeai>=0.3.1->python-aiconfig->lastmile_eval)\n",
      "  Using cached google_api_python_client-2.129.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai>=0.3.1->python-aiconfig->lastmile_eval)\n",
      "  Using cached google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.4->google-generativeai>=0.3.1->python-aiconfig->lastmile_eval)\n",
      "  Using cached proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->lastmile_eval) (1.0.5)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<=7.0,>=6.0->opentelemetry-api->lastmile_eval)\n",
      "  Downloading zipp-3.18.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->lastmile_eval) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->lastmile_eval) (3.10.3)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jsonpath-ng<2.0.0,>=1.6.0 (from llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading jsonpath_ng-1.6.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Using cached llamaindex_py_client-0.1.19-py3-none-any.whl.metadata (760 bytes)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Using cached pillow-10.3.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting spacy<4.0.0,>=3.7.1 (from llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading spacy-3.7.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index->lastmile_eval)\n",
      "  Using cached pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index->lastmile_eval)\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index->lastmile_eval)\n",
      "  Downloading llama_parse-0.4.3-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web->lastmile_eval)\n",
      "  Using cached cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting lxml>=3.6.0 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web->lastmile_eval)\n",
      "  Downloading lxml-5.2.2-cp310-cp310-macosx_10_9_universal2.whl.metadata (3.4 kB)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web->lastmile_eval)\n",
      "  Using cached feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web->lastmile_eval)\n",
      "  Using cached tldextract-5.1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web->lastmile_eval)\n",
      "  Using cached feedfinder2-0.0.4-py3-none-any.whl\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web->lastmile_eval)\n",
      "  Using cached jieba3k-0.35.1-py3-none-any.whl\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web->lastmile_eval)\n",
      "  Using cached tinysegmenter-0.3-py3-none-any.whl\n",
      "Collecting greenlet==3.0.3 (from playwright<2.0,>=1.30->llama-index-readers-web->lastmile_eval)\n",
      "  Using cached greenlet-3.0.3-cp310-cp310-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting pyee==11.1.0 (from playwright<2.0,>=1.30->llama-index-readers-web->lastmile_eval)\n",
      "  Using cached pyee-11.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=13.7.0->instructor->lastmile_eval)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from rich<14.0.0,>=13.7.0->instructor->lastmile_eval) (2.15.1)\n",
      "Collecting trio~=0.17 (from selenium<5.0.0,>=4.17.2->llama-index-readers-web->lastmile_eval)\n",
      "  Downloading trio-0.25.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.17.2->llama-index-readers-web->lastmile_eval)\n",
      "  Using cached trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.9.0->instructor->lastmile_eval)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting boto3>=1.28.57 (from anthropic-bedrock->python-aiconfig->lastmile_eval)\n",
      "  Downloading boto3-1.34.110-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore>=1.31.57 (from anthropic-bedrock->python-aiconfig->lastmile_eval)\n",
      "  Downloading botocore-1.34.110-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting Werkzeug>=3.0.0 (from flask[async]->python-aiconfig->lastmile_eval)\n",
      "  Using cached werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting itsdangerous>=2.1.2 (from flask[async]->python-aiconfig->lastmile_eval)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting blinker>=1.6.2 (from flask[async]->python-aiconfig->lastmile_eval)\n",
      "  Using cached blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting asgiref>=3.2 (from flask[async]->python-aiconfig->lastmile_eval)\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from opentelemetry-instrumentation->openinference-instrumentation-langchain->lastmile_eval) (69.5.1)\n",
      "Requirement already satisfied: wcwidth in /opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages (from prompt-toolkit->python-aiconfig->lastmile_eval) (0.2.5)\n",
      "Collecting PyMeta3>=0.5.1 (from pybars3->python-aiconfig->lastmile_eval)\n",
      "  Using cached PyMeta3-0.5.1-py3-none-any.whl\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->python-aiconfig->lastmile_eval)\n",
      "  Using cached ruamel.yaml.clib-0.2.8-cp310-cp310-macosx_13_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.28.57->anthropic-bedrock->python-aiconfig->lastmile_eval)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.28.57->anthropic-bedrock->python-aiconfig->lastmile_eval)\n",
      "  Using cached s3transfer-0.10.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web->lastmile_eval)\n",
      "  Using cached sgmllib3k-1.0.0-py3-none-any.whl\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai>=0.3.1->python-aiconfig->lastmile_eval)\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai>=0.3.1->python-aiconfig->lastmile_eval)\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai>=0.3.1->python-aiconfig->lastmile_eval)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting ply (from jsonpath-ng<2.0.0,>=1.6.0->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl.metadata (844 bytes)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor->lastmile_eval)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading murmurhash-1.0.10-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading cymem-2.0.8-cp310-cp310-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading preshed-3.0.9-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading thinc-8.2.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading srsly-2.4.8-cp310-cp310-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<1.0.0,>=0.9.0 (from instructor->lastmile_eval)\n",
      "  Using cached typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Using cached smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web->lastmile_eval)\n",
      "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web->lastmile_eval)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.17.2->llama-index-readers-web->lastmile_eval)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium<5.0.0,>=4.17.2->llama-index-readers-web->lastmile_eval)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai>=0.3.1->python-aiconfig->lastmile_eval)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai>=0.3.1->python-aiconfig->lastmile_eval)\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai>=0.3.1->python-aiconfig->lastmile_eval)\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai>=0.3.1->python-aiconfig->lastmile_eval)\n",
      "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai>=0.3.1->python-aiconfig->lastmile_eval)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai>=0.3.1->python-aiconfig->lastmile_eval)\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading blis-0.7.11-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai>=0.3.1->python-aiconfig->lastmile_eval)\n",
      "  Using cached grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.7.1->llama-index-core<0.11.0,>=0.10.35->llama-index->lastmile_eval)\n",
      "  Downloading marisa_trie-1.1.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (8.6 kB)\n",
      "Downloading lastmile_eval-0.0.44-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached arize_phoenix_evals-0.5.0-py3-none-any.whl (45 kB)\n",
      "Using cached email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Using cached evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "Using cached fastapi-0.110.1-py3-none-any.whl (91 kB)\n",
      "Using cached pandas-2.1.2-cp310-cp310-macosx_11_0_arm64.whl (10.9 MB)\n",
      "Downloading anthropic-0.26.1-py3-none-any.whl (877 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m877.6/877.6 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Downloading instructor-1.2.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached lastmile_utils-0.0.24-py3-none-any.whl (15 kB)\n",
      "Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Using cached result-0.16.0-py3-none-any.whl (6.8 kB)\n",
      "Using cached autoflake-2.2.1-py3-none-any.whl (32 kB)\n",
      "Using cached black-23.11.0-cp310-cp310-macosx_11_0_arm64.whl (1.4 MB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached flake8-6.1.0-py2.py3-none-any.whl (58 kB)\n",
      "Using cached isort-5.12.0-py3-none-any.whl (91 kB)\n",
      "Using cached pylint-3.0.2-py3-none-any.whl (510 kB)\n",
      "Using cached pyright-1.1.335-py3-none-any.whl (17 kB)\n",
      "Using cached pytest-7.4.3-py3-none-any.whl (325 kB)\n",
      "Downloading llama_index-0.10.37-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n",
      "Using cached llama_index_callbacks_openinference-0.1.4-py3-none-any.whl (4.2 kB)\n",
      "Downloading llama_index_readers_web-0.1.16-py3-none-any.whl (69 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
      "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading openinference_instrumentation_langchain-0.1.16-py3-none-any.whl (14 kB)\n",
      "Downloading openinference_instrumentation_llama_index-1.4.1-py3-none-any.whl (22 kB)\n",
      "Using cached openinference_semantic_conventions-0.1.6-py3-none-any.whl (8.5 kB)\n",
      "Using cached opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
      "Using cached opentelemetry_exporter_otlp-1.24.0-py3-none-any.whl (7.0 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_http-1.24.0-py3-none-any.whl (16 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
      "Using cached opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
      "Downloading pyarrow-16.1.0-cp310-cp310-macosx_11_0_arm64.whl (26.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached python_aiconfig-1.1.34-py3-none-any.whl (1.6 MB)\n",
      "Using cached hypothesis-6.91.0-py3-none-any.whl (423 kB)\n",
      "Using cached uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "Using cached chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Downloading google_generativeai-0.5.4-py3-none-any.whl (150 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_ai_generativelanguage-0.6.4-py3-none-any.whl (679 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.1/679.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "Using cached importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
      "Downloading jiter-0.1.0-cp310-cp310-macosx_11_0_arm64.whl (270 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.5/270.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_agent_openai-0.2.5-py3-none-any.whl (13 kB)\n",
      "Using cached llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
      "Downloading llama_index_core-0.10.37.post1-py3-none-any.whl (15.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
      "Using cached llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "Downloading llama_index_llms_openai-0.1.20-py3-none-any.whl (11 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl (5.8 kB)\n",
      "Using cached llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
      "Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Using cached llama_index_readers_file-0.1.22-py3-none-any.whl (36 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp310-cp310-macosx_10_9_universal2.whl (18 kB)\n",
      "Using cached newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "Downloading openinference_instrumentation-0.1.7-py3-none-any.whl (8.4 kB)\n",
      "Downloading playwright-1.44.0-py3-none-macosx_11_0_arm64.whl (33.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.0/33.0 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached greenlet-3.0.3-cp310-cp310-macosx_11_0_universal2.whl (270 kB)\n",
      "Using cached pyee-11.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Downloading selenium-4.21.0-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "Using cached tokenizers-0.19.1-cp310-cp310-macosx_11_0_arm64.whl (2.4 MB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached wrapt-1.16.0-cp310-cp310-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached anthropic_bedrock-0.8.0-py3-none-any.whl (820 kB)\n",
      "Using cached Flask_Cors-4.0.1-py2.py3-none-any.whl (14 kB)\n",
      "Using cached frozendict-2.4.4-cp310-cp310-macosx_11_0_arm64.whl (37 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
      "Using cached ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
      "Using cached xxhash-3.4.1-cp310-cp310-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached astroid-3.0.3-py3-none-any.whl (275 kB)\n",
      "Using cached blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Downloading boto3-1.34.110-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.110-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Using cached flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "Using cached google_api_core-2.19.0-py3-none-any.whl (139 kB)\n",
      "Using cached google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading grpcio-1.64.0-cp310-cp310-macosx_12_0_universal2.whl (10.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading jsonpath_ng-1.6.1-py3-none-any.whl (29 kB)\n",
      "Downloading llama_parse-0.4.3-py3-none-any.whl (7.7 kB)\n",
      "Using cached llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
      "Downloading lxml-5.2.2-cp310-cp310-macosx_10_9_universal2.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
      "Using cached pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Using cached pillow-10.3.0-cp310-cp310-macosx_11_0_arm64.whl (3.4 MB)\n",
      "Using cached pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n",
      "Using cached pyflakes-3.1.0-py2.py3-none-any.whl (62 kB)\n",
      "Using cached pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "Using cached ruamel.yaml.clib-0.2.8-cp310-cp310-macosx_13_0_arm64.whl (133 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy-3.7.4-cp310-cp310-macosx_11_0_arm64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
      "Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Downloading tomlkit-0.12.5-py3-none-any.whl (37 kB)\n",
      "Downloading trio-0.25.1-py3-none-any.whl (467 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.7/467.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Using cached werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "Downloading zipp-3.18.2-py3-none-any.whl (8.3 kB)\n",
      "Using cached google_api_python_client-2.129.0-py2.py3-none-any.whl (11.6 MB)\n",
      "Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp310-cp310-macosx_11_0_arm64.whl (41 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.0/182.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading murmurhash-1.0.10-cp310-cp310-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading preshed-3.0.9-cp310-cp310-macosx_11_0_arm64.whl (127 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.8/127.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "Using cached smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp310-cp310-macosx_11_0_arm64.whl (491 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.2.3-cp310-cp310-macosx_11_0_arm64.whl (789 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.6/789.6 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-0.7.11-cp310-cp310-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Using cached grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
      "Downloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Downloading marisa_trie-1.1.1-cp310-cp310-macosx_11_0_arm64.whl (174 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.9/174.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tinysegmenter, striprtf, sortedcontainers, sgmllib3k, pytz, PyMeta3, ply, jieba3k, dirtyjson, dataclasses, cymem, zipp, xxhash, wsproto, wrapt, wasabi, uritemplate, tzdata, tomlkit, tomli, spacy-loggers, spacy-legacy, smart-open, ruamel.yaml.clib, result, python-dotenv, pysocks, pypdf, pyparsing, pyflakes, pyee, pycodestyle, pybars3, pyasn1, pyarrow-hotfix, pyarrow, protobuf, pluggy, pillow, pathspec, outcome, opentelemetry-semantic-conventions, openinference-semantic-conventions, nodeenv, networkx, murmurhash, mdurl, mccabe, MarkupSafe, marisa-trie, lxml, jsonpath-ng, joblib, jmespath, jiter, itsdangerous, isort, iniconfig, hypothesis, html2text, grpcio, greenlet, fsspec, frozendict, filelock, feedparser, docstring-parser, dnspython, dill, cssselect, cloudpathlib, click, chromedriver-autoinstaller, chardet, catalogue, cachetools, blis, blinker, astroid, asgiref, absl-py, Werkzeug, uvicorn, typer, trio, starlette, srsly, spider-client, ruamel.yaml, rsa, responses, requests-file, pytest, pyright, pylint, pyasn1-modules, proto-plus, preshed, playwright, pandas, opentelemetry-proto, nltk, multiprocess, markdown-it-py, language-data, jinja2, importlib-metadata, huggingface-hub, httplib2, googleapis-common-protos, flake8, feedfinder2, email-validator, deprecated, botocore, black, autoflake, trio-websocket, tokenizers, tldextract, s3transfer, rouge-score, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, llamaindex-py-client, lastmile-utils, langcodes, grpcio-status, google-auth, flask, fastapi, confection, arize-phoenix-evals, weasel, thinc, selenium, opentelemetry-sdk, opentelemetry-instrumentation, openinference-instrumentation, newspaper3k, llama-index-legacy, instructor, google-auth-httplib2, google-api-core, flask-cors, datasets, boto3, anthropic, spacy, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, openinference-instrumentation-llama-index, openinference-instrumentation-langchain, google-api-python-client, evaluate, anthropic-bedrock, opentelemetry-exporter-otlp, llama-index-core, google-ai-generativelanguage, llama-parse, llama-index-readers-web, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-callbacks-openinference, google-generativeai, python-aiconfig, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index, lastmile_eval\n",
      "Successfully installed MarkupSafe-2.1.5 PyMeta3-0.5.1 Werkzeug-3.0.3 absl-py-2.1.0 anthropic-0.26.1 anthropic-bedrock-0.8.0 arize-phoenix-evals-0.5.0 asgiref-3.8.1 astroid-3.0.3 autoflake-2.2.1 black-23.11.0 blinker-1.8.2 blis-0.7.11 boto3-1.34.110 botocore-1.34.110 cachetools-5.3.3 catalogue-2.0.10 chardet-5.2.0 chromedriver-autoinstaller-0.6.4 click-8.1.7 cloudpathlib-0.16.0 confection-0.1.4 cssselect-1.2.0 cymem-2.0.8 dataclasses-0.6 datasets-2.19.1 deprecated-1.2.14 dill-0.3.8 dirtyjson-1.0.8 dnspython-2.6.1 docstring-parser-0.16 email-validator-2.1.1 evaluate-0.4.1 fastapi-0.110.1 feedfinder2-0.0.4 feedparser-6.0.11 filelock-3.14.0 flake8-6.1.0 flask-3.0.3 flask-cors-4.0.1 frozendict-2.4.4 fsspec-2024.3.1 google-ai-generativelanguage-0.6.4 google-api-core-2.19.0 google-api-python-client-2.129.0 google-auth-2.29.0 google-auth-httplib2-0.2.0 google-generativeai-0.5.4 googleapis-common-protos-1.63.0 greenlet-3.0.3 grpcio-1.64.0 grpcio-status-1.62.2 html2text-2020.1.16 httplib2-0.22.0 huggingface-hub-0.21.4 hypothesis-6.91.0 importlib-metadata-7.0.0 iniconfig-2.0.0 instructor-1.2.6 isort-5.12.0 itsdangerous-2.2.0 jieba3k-0.35.1 jinja2-3.1.4 jiter-0.1.0 jmespath-1.0.1 joblib-1.4.2 jsonpath-ng-1.6.1 langcodes-3.4.0 language-data-1.2.0 lastmile-utils-0.0.24 lastmile_eval-0.0.44 llama-index-0.10.37 llama-index-agent-openai-0.2.5 llama-index-callbacks-openinference-0.1.4 llama-index-cli-0.1.12 llama-index-core-0.10.37.post1 llama-index-embeddings-openai-0.1.10 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.20 llama-index-multi-modal-llms-openai-0.1.6 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.22 llama-index-readers-llama-parse-0.1.4 llama-index-readers-web-0.1.16 llama-parse-0.4.3 llamaindex-py-client-0.1.19 lxml-5.2.2 marisa-trie-1.1.1 markdown-it-py-3.0.0 mccabe-0.7.0 mdurl-0.1.2 multiprocess-0.70.16 murmurhash-1.0.10 networkx-3.3 newspaper3k-0.2.8 nltk-3.8.1 nodeenv-1.8.0 openinference-instrumentation-0.1.7 openinference-instrumentation-langchain-0.1.16 openinference-instrumentation-llama-index-1.4.1 openinference-semantic-conventions-0.1.6 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-exporter-otlp-proto-http-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 outcome-1.3.0.post0 pandas-2.1.2 pathspec-0.12.1 pillow-10.3.0 playwright-1.44.0 pluggy-1.5.0 ply-3.11 preshed-3.0.9 proto-plus-1.23.0 protobuf-4.25.3 pyarrow-16.1.0 pyarrow-hotfix-0.6 pyasn1-0.6.0 pyasn1-modules-0.4.0 pybars3-0.9.7 pycodestyle-2.11.1 pyee-11.1.0 pyflakes-3.1.0 pylint-3.0.2 pyparsing-3.1.2 pypdf-4.2.0 pyright-1.1.335 pysocks-1.7.1 pytest-7.4.3 python-aiconfig-1.1.34 python-dotenv-1.0.0 pytz-2024.1 requests-file-2.1.0 responses-0.18.0 result-0.16.0 rich-13.7.1 rouge-score-0.1.2 rsa-4.9 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 s3transfer-0.10.1 selenium-4.21.0 sgmllib3k-1.0.0 smart-open-6.4.0 sortedcontainers-2.4.0 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 spider-client-0.0.11 srsly-2.4.8 starlette-0.37.2 striprtf-0.0.26 thinc-8.2.3 tinysegmenter-0.3 tldextract-5.1.2 tokenizers-0.19.1 tomli-2.0.1 tomlkit-0.12.5 trio-0.25.1 trio-websocket-0.11.1 typer-0.9.4 tzdata-2024.1 uritemplate-4.1.1 uvicorn-0.29.0 wasabi-1.1.2 weasel-0.3.4 wrapt-1.16.0 wsproto-1.2.0 xxhash-3.4.1 zipp-3.18.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain_community\n",
    "!pip install langchain_core\n",
    "!pip install langchain_experimental\n",
    "!pip install langchain_openai\n",
    "!pip install wikipedia\n",
    "!pip install numexpr\n",
    "\n",
    "!pip install \"tracing_auto_instrumentation[langchain]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_experimental.plan_and_execute import (\n",
    "    PlanAndExecute,\n",
    "    load_agent_executor,\n",
    "    load_chat_planner,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI, OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LastMile Auto Instrumentation Setup\n",
    "\n",
    "An instance of `LangChainInstrumentor` is created with a project name. The `instrument()` method is called to instrument the code for tracing and monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 20:55:19,331 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:55:19,477 - https://lastmileai.dev:443 \"GET /api/evaluation_projects/list?name=Plan-and-Execute+Example HTTP/1.1\" 200 41\n",
      "2024-05-21 20:55:19,479 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:55:19,564 - https://lastmileai.dev:443 \"POST /api/evaluation_projects/create HTTP/1.1\" 200 261\n"
     ]
    }
   ],
   "source": [
    "from tracing_auto_instrumentation.langchain import LangChainInstrumentor\n",
    "\n",
    "# Create an instance of LangChainInstrumentor and instrument the code\n",
    "instrumentor = LangChainInstrumentor(project_name=\"Plan-and-Execute Example\")\n",
    "instrumentor.instrument()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "\n",
    "The tools that the agent will use for executing sub-tasks are defined. In this example, we have two tools:\n",
    "- \"Wikipedia\" tool: Uses the `WikipediaAPIWrapper` to look up information on Wikipedia.\n",
    "- \"Calculator\" tool: Uses the `LLMMathChain` to perform mathematical calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 20:57:37,896 - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-05-21 20:57:37,897 - load_verify_locations cafile='/opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "2024-05-21 20:57:37,921 - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-05-21 20:57:37,922 - load_verify_locations cafile='/opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages/certifi/cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "# Define the tools that the agent will use for executing sub-tasks\n",
    "\n",
    "wikipedia = WikipediaAPIWrapper()\n",
    "llm = OpenAI(temperature=0)\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Wikipedia\",\n",
    "        func=wikipedia.run,\n",
    "        description=\"useful for when you need to look up information on Wikipedia\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to perform mathematical calculations\",\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Example\n",
    "\n",
    "The agent is run with a sample question that involves looking up the population of the capital city of the country where the Eiffel Tower is located and calculating the square root of that number. The result is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 20:57:40,539 - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-05-21 20:57:40,541 - load_verify_locations cafile='/opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "2024-05-21 20:57:40,568 - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-05-21 20:57:40,569 - load_verify_locations cafile='/opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/tai1/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "2024-05-21 20:57:40,611 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': \"Let's first understand the problem and devise a plan to solve the problem. Please output the plan starting with the header 'Plan:' and then followed by a numbered list of steps. Please make the plan the minimum number of steps required to accurately complete the task. If the task is a question, the final step should almost always be 'Given the above steps taken, please respond to the users original question'. At the end of your plan, say '<END_OF_PLAN>'\", 'role': 'system'}, {'content': 'What is the population of the capital city of the country where the Eiffel Tower is located? Calculate the square root of that number.', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stop': ['<END_OF_PLAN>'], 'stream': False, 'temperature': 0.0}}\n",
      "2024-05-21 20:57:40,619 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-05-21 20:57:40,620 - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2024-05-21 20:57:40,645 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x29dd5bc70>\n",
      "2024-05-21 20:57:40,646 - start_tls.started ssl_context=<ssl.SSLContext object at 0x29e107940> server_hostname='api.openai.com' timeout=None\n",
      "2024-05-21 20:57:40,656 - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x29e1cce50>\n",
      "2024-05-21 20:57:40,657 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:40,657 - send_request_headers.complete\n",
      "2024-05-21 20:57:40,658 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:40,658 - send_request_body.complete\n",
      "2024-05-21 20:57:40,658 - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:42,231 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 22 May 2024 00:57:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'lastmile-ai'), (b'openai-processing-ms', b'1388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999834'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'4ms'), (b'x-request-id', b'req_76c51c7813c42d7e997cb047619cbc9c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Iv64hIhP8WY72I8y6BcMOYH5sX_jMw9r4Ae37P1fRTs-1716339462-1.0.1.1-OkEOhynsABGIk_5yKwd54bQ.znLnL5zGzIpKajphp2yOHoC2p9U5eYfvdMPUPElZJt1DT3a_j8a3kEvlS.jUfA; path=/; expires=Wed, 22-May-24 01:27:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=lSN4GmN9MYmvxaooQpBWR6MAtixsYE1SDPuEC0FBcWA-1716339462174-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8878da7d3f868cd7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-05-21 20:57:42,233 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-21 20:57:42,234 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:42,235 - receive_response_body.complete\n",
      "2024-05-21 20:57:42,236 - response_closed.started\n",
      "2024-05-21 20:57:42,236 - response_closed.complete\n",
      "2024-05-21 20:57:42,236 - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Wed, 22 May 2024 00:57:42 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('openai-organization', 'lastmile-ai'), ('openai-processing-ms', '1388'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=15724800; includeSubDomains'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '2000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '1999834'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '4ms'), ('x-request-id', 'req_76c51c7813c42d7e997cb047619cbc9c'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Iv64hIhP8WY72I8y6BcMOYH5sX_jMw9r4Ae37P1fRTs-1716339462-1.0.1.1-OkEOhynsABGIk_5yKwd54bQ.znLnL5zGzIpKajphp2yOHoC2p9U5eYfvdMPUPElZJt1DT3a_j8a3kEvlS.jUfA; path=/; expires=Wed, 22-May-24 01:27:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('set-cookie', '_cfuvid=lSN4GmN9MYmvxaooQpBWR6MAtixsYE1SDPuEC0FBcWA-1716339462174-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8878da7d3f868cd7-EWR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "2024-05-21 20:57:42,237 - request_id: req_76c51c7813c42d7e997cb047619cbc9c\n",
      "2024-05-21 20:57:42,252 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:42,390 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:42,492 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:42,504 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nWikipedia: useful for when you need to look up information on Wikipedia, args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\nCalculator: useful for when you need to perform mathematical calculations, args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or Wikipedia, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:', 'role': 'system'}, {'content': \"Previous steps: steps=[]\\n\\nCurrent objective: value='Identify the country where the Eiffel Tower is located.'\\n\\n\", 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stop': ['Observation:'], 'stream': False, 'temperature': 0.0}}\n",
      "2024-05-21 20:57:42,505 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-05-21 20:57:42,506 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:42,506 - send_request_headers.complete\n",
      "2024-05-21 20:57:42,507 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:42,507 - send_request_body.complete\n",
      "2024-05-21 20:57:42,507 - receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 20:57:43,253 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 22 May 2024 00:57:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'lastmile-ai'), (b'openai-processing-ms', b'538'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999667'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'9ms'), (b'x-request-id', b'req_093e024ef74d3596e6ae7e6ccd8b0fdc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8878da88cbd98cd7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-05-21 20:57:43,254 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-21 20:57:43,255 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:43,255 - receive_response_body.complete\n",
      "2024-05-21 20:57:43,256 - response_closed.started\n",
      "2024-05-21 20:57:43,256 - response_closed.complete\n",
      "2024-05-21 20:57:43,256 - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 22 May 2024 00:57:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'lastmile-ai', 'openai-processing-ms': '538', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999667', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '9ms', 'x-request-id': 'req_093e024ef74d3596e6ae7e6ccd8b0fdc', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8878da88cbd98cd7-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-05-21 20:57:43,257 - request_id: req_093e024ef74d3596e6ae7e6ccd8b0fdc\n",
      "2024-05-21 20:57:43,310 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:44,533 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:44,652 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:44,663 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nWikipedia: useful for when you need to look up information on Wikipedia, args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\nCalculator: useful for when you need to perform mathematical calculations, args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or Wikipedia, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:', 'role': 'system'}, {'content': \"Previous steps: steps=[(Step(value='Identify the country where the Eiffel Tower is located.'), StepResponse(response='France'))]\\n\\nCurrent objective: value='Determine the capital city of that country.'\\n\\n\", 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stop': ['Observation:'], 'stream': False, 'temperature': 0.0}}\n",
      "2024-05-21 20:57:44,664 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-05-21 20:57:44,665 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:44,665 - send_request_headers.complete\n",
      "2024-05-21 20:57:44,666 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:44,666 - send_request_body.complete\n",
      "2024-05-21 20:57:44,666 - receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: The Eiffel Tower is located in France.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"France\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 20:57:45,711 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 22 May 2024 00:57:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'lastmile-ai'), (b'openai-processing-ms', b'780'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999644'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_7b1cff78891fa58154f59a5fbc41eb39'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8878da9649618cd7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-05-21 20:57:45,713 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-21 20:57:45,714 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:45,715 - receive_response_body.complete\n",
      "2024-05-21 20:57:45,716 - response_closed.started\n",
      "2024-05-21 20:57:45,716 - response_closed.complete\n",
      "2024-05-21 20:57:45,716 - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 22 May 2024 00:57:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'lastmile-ai', 'openai-processing-ms': '780', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999644', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '10ms', 'x-request-id': 'req_7b1cff78891fa58154f59a5fbc41eb39', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8878da9649618cd7-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-05-21 20:57:45,717 - request_id: req_7b1cff78891fa58154f59a5fbc41eb39\n",
      "2024-05-21 20:57:45,751 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:45,778 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:45,780 - Starting new HTTP connection (1): en.wikipedia.org:80\n",
      "2024-05-21 20:57:45,823 - http://en.wikipedia.org:80 \"GET /w/api.php?list=search&srprop=&srlimit=3&limit=3&srsearch=Capital+of+France&format=json&action=query HTTP/1.1\" 301 0\n",
      "2024-05-21 20:57:45,825 - Starting new HTTPS connection (1): en.wikipedia.org:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I can use Wikipedia to quickly find the capital city of France.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"Capital of France\"\n",
      "}\n",
      "```\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 20:57:46,326 - https://en.wikipedia.org:443 \"GET /w/api.php?list=search&srprop=&srlimit=3&limit=3&srsearch=Capital+of+France&format=json&action=query HTTP/1.1\" 200 351\n",
      "2024-05-21 20:57:46,330 - Starting new HTTP connection (1): en.wikipedia.org:80\n",
      "2024-05-21 20:57:46,354 - http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=List+of+capitals+of+France&format=json&action=query HTTP/1.1\" 301 0\n",
      "2024-05-21 20:57:46,356 - Starting new HTTPS connection (1): en.wikipedia.org:443\n",
      "2024-05-21 20:57:46,445 - https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=List+of+capitals+of+France&format=json&action=query HTTP/1.1\" 200 516\n",
      "2024-05-21 20:57:46,449 - Starting new HTTP connection (1): en.wikipedia.org:80\n",
      "2024-05-21 20:57:46,474 - http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts&explaintext=&exintro=&titles=List+of+capitals+of+France&format=json&action=query HTTP/1.1\" 301 0\n",
      "2024-05-21 20:57:46,475 - Starting new HTTPS connection (1): en.wikipedia.org:443\n",
      "2024-05-21 20:57:46,560 - https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts&explaintext=&exintro=&titles=List+of+capitals+of+France&format=json&action=query HTTP/1.1\" 200 242\n",
      "2024-05-21 20:57:46,563 - Starting new HTTP connection (1): en.wikipedia.org:80\n",
      "2024-05-21 20:57:46,588 - http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Capital+punishment+in+France&format=json&action=query HTTP/1.1\" 301 0\n",
      "2024-05-21 20:57:46,589 - Starting new HTTPS connection (1): en.wikipedia.org:443\n",
      "2024-05-21 20:57:46,673 - https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Capital+punishment+in+France&format=json&action=query HTTP/1.1\" 200 527\n",
      "2024-05-21 20:57:46,675 - Starting new HTTP connection (1): en.wikipedia.org:80\n",
      "2024-05-21 20:57:46,699 - http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts&explaintext=&exintro=&titles=Capital+punishment+in+France&format=json&action=query HTTP/1.1\" 301 0\n",
      "2024-05-21 20:57:46,700 - Starting new HTTPS connection (1): en.wikipedia.org:443\n",
      "2024-05-21 20:57:46,780 - https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts&explaintext=&exintro=&titles=Capital+punishment+in+France&format=json&action=query HTTP/1.1\" 200 690\n",
      "2024-05-21 20:57:46,783 - Starting new HTTP connection (1): en.wikipedia.org:80\n",
      "2024-05-21 20:57:46,807 - http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Capital+city&format=json&action=query HTTP/1.1\" 301 0\n",
      "2024-05-21 20:57:46,808 - Starting new HTTPS connection (1): en.wikipedia.org:443\n",
      "2024-05-21 20:57:46,892 - https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Capital+city&format=json&action=query HTTP/1.1\" 200 461\n",
      "2024-05-21 20:57:46,895 - Starting new HTTP connection (1): en.wikipedia.org:80\n",
      "2024-05-21 20:57:46,918 - http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts&explaintext=&exintro=&titles=Capital+city&format=json&action=query HTTP/1.1\" 301 0\n",
      "2024-05-21 20:57:46,920 - Starting new HTTPS connection (1): en.wikipedia.org:443\n",
      "2024-05-21 20:57:47,014 - https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts&explaintext=&exintro=&titles=Capital+city&format=json&action=query HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:47,044 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:47,051 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nWikipedia: useful for when you need to look up information on Wikipedia, args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\nCalculator: useful for when you need to perform mathematical calculations, args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or Wikipedia, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:', 'role': 'system'}, {'content': 'Previous steps: steps=[(Step(value=\\'Identify the country where the Eiffel Tower is located.\\'), StepResponse(response=\\'France\\'))]\\n\\nCurrent objective: value=\\'Determine the capital city of that country.\\'\\n\\nThis was your previous work (but I haven\\'t seen any of it! I only see what you return as final answer):\\nThought: I can use Wikipedia to quickly find the capital city of France.\\nAction:\\n```\\n{\\n  \"action\": \"Wikipedia\",\\n  \"action_input\": \"Capital of France\"\\n}\\n```\\nObservation: Page: List of capitals of France\\nSummary: This is a chronological list of capitals of France. The capital of France has been Paris since its liberation in 1944.\\n\\nPage: Capital punishment in France\\nSummary: Capital punishment in France (French: peine de mort en France) is banned by Article 66-1 of the Constitution of the French Republic, voted as a constitutional amendment by the Congress of the French Parliament on 19 February 2007 and simply stating \"No one can be sentenced to the death penalty\" (French: Nul ne peut être condamné à la peine de mort). The death penalty was already declared illegal on 9 October 1981 when President François Mitterrand signed a law prohibiting the judicial system from using it and commuting the sentences of the seven people on death row to life imprisonment. The last execution took place by guillotine, being the main legal method since the French Revolution; Hamida Djandoubi, a Tunisian citizen convicted of torture and murder on French soil, was put to death in September 1977 in Marseille.\\nMajor French death penalty abolitionists across time have included philosopher Voltaire; poet Victor Hugo; politicians Léon Gambetta, Jean Jaurès and Aristide Briand; and writers Alphonse de Lamartine and Albert Camus.\\n\\nPage: Capital city\\nSummary: A capital city or just capital is the municipality holding primary status in a country, state, province, department, or other subnational division, usually as its seat of the government. A capital is typically a city that physically encompasses the government\\'s offices and meeting places; the status as capital is often designated by its law or constitution. In some jurisdictions, including several countries, different branches of government are in different settlements, sometimes meaning multiple official capitals. In some cases, a distinction is made between the official (constitutional) capital and the seat of government, which is in another place. \\nEnglish-language news media often use the name of the capital city as an alternative name for the government of the country of which it is the capital, as a form of metonymy. For example, the \"relations between London and Washington\" refers to the \"relations between the United Kingdom and the United States\".\\nThought:', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stop': ['Observation:'], 'stream': False, 'temperature': 0.0}}\n",
      "2024-05-21 20:57:47,052 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-05-21 20:57:47,053 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:47,053 - send_request_headers.complete\n",
      "2024-05-21 20:57:47,054 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:47,054 - send_request_body.complete\n",
      "2024-05-21 20:57:47,054 - receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: List of capitals of France\n",
      "Summary: This is a chronological list of capitals of France. The capital of France has been Paris since its liberation in 1944.\n",
      "\n",
      "Page: Capital punishment in France\n",
      "Summary: Capital punishment in France (French: peine de mort en France) is banned by Article 66-1 of the Constitution of the French Republic, voted as a constitutional amendment by the Congress of the French Parliament on 19 February 2007 and simply stating \"No one can be sentenced to the death penalty\" (French: Nul ne peut être condamné à la peine de mort). The death penalty was already declared illegal on 9 October 1981 when President François Mitterrand signed a law prohibiting the judicial system from using it and commuting the sentences of the seven people on death row to life imprisonment. The last execution took place by guillotine, being the main legal method since the French Revolution; Hamida Djandoubi, a Tunisian citizen convicted of torture and murder on French soil, was put to death in September 1977 in Marseille.\n",
      "Major French death penalty abolitionists across time have included philosopher Voltaire; poet Victor Hugo; politicians Léon Gambetta, Jean Jaurès and Aristide Briand; and writers Alphonse de Lamartine and Albert Camus.\n",
      "\n",
      "Page: Capital city\n",
      "Summary: A capital city or just capital is the municipality holding primary status in a country, state, province, department, or other subnational division, usually as its seat of the government. A capital is typically a city that physically encompasses the government's offices and meeting places; the status as capital is often designated by its law or constitution. In some jurisdictions, including several countries, different branches of government are in different settlements, sometimes meaning multiple official capitals. In some cases, a distinction is made between the official (constitutional) capital and the seat of government, which is in another place. \n",
      "English-language news media often use the name of the capital city as an alternative name for the government of the country of which it is the capital, as a form of metonymy. For example, the \"relations between London and Washington\" refers to the \"relations between the United Kingdom and the United States\".\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 20:57:48,301 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 22 May 2024 00:57:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'lastmile-ai'), (b'openai-processing-ms', b'1097'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999009'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'29ms'), (b'x-request-id', b'req_29a8d639ca99a726eb32f979c81373e5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8878daa5397f8cd7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-05-21 20:57:48,303 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-21 20:57:48,304 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:48,305 - receive_response_body.complete\n",
      "2024-05-21 20:57:48,306 - response_closed.started\n",
      "2024-05-21 20:57:48,306 - response_closed.complete\n",
      "2024-05-21 20:57:48,307 - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 22 May 2024 00:57:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'lastmile-ai', 'openai-processing-ms': '1097', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999009', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '29ms', 'x-request-id': 'req_29a8d639ca99a726eb32f979c81373e5', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8878daa5397f8cd7-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-05-21 20:57:48,307 - request_id: req_29a8d639ca99a726eb32f979c81373e5\n",
      "2024-05-21 20:57:48,338 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:48,367 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:48,395 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:48,402 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nWikipedia: useful for when you need to look up information on Wikipedia, args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\nCalculator: useful for when you need to perform mathematical calculations, args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or Wikipedia, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:', 'role': 'system'}, {'content': \"Previous steps: steps=[(Step(value='Identify the country where the Eiffel Tower is located.'), StepResponse(response='France')), (Step(value='Determine the capital city of that country.'), StepResponse(response='Paris'))]\\n\\nCurrent objective: value='Find the population of the capital city.'\\n\\n\", 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stop': ['Observation:'], 'stream': False, 'temperature': 0.0}}\n",
      "2024-05-21 20:57:48,403 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-05-21 20:57:48,403 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:48,404 - send_request_headers.complete\n",
      "2024-05-21 20:57:48,404 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:48,404 - send_request_body.complete\n",
      "2024-05-21 20:57:48,404 - receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI have found information about the capital of France, which is Paris. Would you like me to provide this as the final answer?\n",
      "Thought: The final answer is ready.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Paris\"\n",
      "}\n",
      "``` \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 20:57:49,302 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 22 May 2024 00:57:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'lastmile-ai'), (b'openai-processing-ms', b'705'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999621'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'11ms'), (b'x-request-id', b'req_301eb79acd711f95d4cfc6a0f594cae1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8878daadaad98cd7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-05-21 20:57:49,303 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-21 20:57:49,304 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:49,305 - receive_response_body.complete\n",
      "2024-05-21 20:57:49,305 - response_closed.started\n",
      "2024-05-21 20:57:49,305 - response_closed.complete\n",
      "2024-05-21 20:57:49,306 - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 22 May 2024 00:57:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'lastmile-ai', 'openai-processing-ms': '705', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999621', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '11ms', 'x-request-id': 'req_301eb79acd711f95d4cfc6a0f594cae1', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8878daadaad98cd7-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-05-21 20:57:49,306 - request_id: req_301eb79acd711f95d4cfc6a0f594cae1\n",
      "2024-05-21 20:57:49,335 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:49,361 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:49,363 - Starting new HTTP connection (1): en.wikipedia.org:80\n",
      "2024-05-21 20:57:49,387 - http://en.wikipedia.org:80 \"GET /w/api.php?list=search&srprop=&srlimit=3&limit=3&srsearch=Population+of+Paris&format=json&action=query HTTP/1.1\" 301 0\n",
      "2024-05-21 20:57:49,388 - Starting new HTTPS connection (1): en.wikipedia.org:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I can use Wikipedia to look up the population of Paris, the capital city of France.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"Population of Paris\"\n",
      "}\n",
      "```\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 20:57:49,808 - https://en.wikipedia.org:443 \"GET /w/api.php?list=search&srprop=&srlimit=3&limit=3&srsearch=Population+of+Paris&format=json&action=query HTTP/1.1\" 200 335\n",
      "2024-05-21 20:57:49,814 - Starting new HTTP connection (1): en.wikipedia.org:80\n",
      "2024-05-21 20:57:49,840 - http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Demographics+of+Paris&format=json&action=query HTTP/1.1\" 301 0\n",
      "2024-05-21 20:57:49,841 - Starting new HTTPS connection (1): en.wikipedia.org:443\n",
      "2024-05-21 20:57:49,933 - https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Demographics+of+Paris&format=json&action=query HTTP/1.1\" 200 499\n",
      "2024-05-21 20:57:49,938 - Starting new HTTP connection (1): en.wikipedia.org:80\n",
      "2024-05-21 20:57:49,962 - http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts&explaintext=&exintro=&titles=Demographics+of+Paris&format=json&action=query HTTP/1.1\" 301 0\n",
      "2024-05-21 20:57:49,964 - Starting new HTTPS connection (1): en.wikipedia.org:443\n",
      "2024-05-21 20:57:50,047 - https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts&explaintext=&exintro=&titles=Demographics+of+Paris&format=json&action=query HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:50,050 - Starting new HTTP connection (1): en.wikipedia.org:80\n",
      "2024-05-21 20:57:50,073 - http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Paris&format=json&action=query HTTP/1.1\" 301 0\n",
      "2024-05-21 20:57:50,075 - Starting new HTTPS connection (1): en.wikipedia.org:443\n",
      "2024-05-21 20:57:50,164 - https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Paris&format=json&action=query HTTP/1.1\" 200 432\n",
      "2024-05-21 20:57:50,167 - Starting new HTTP connection (1): en.wikipedia.org:80\n",
      "2024-05-21 20:57:50,193 - http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts&explaintext=&exintro=&titles=Paris&format=json&action=query HTTP/1.1\" 301 0\n",
      "2024-05-21 20:57:50,195 - Starting new HTTPS connection (1): en.wikipedia.org:443\n",
      "2024-05-21 20:57:50,288 - https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts&explaintext=&exintro=&titles=Paris&format=json&action=query HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:50,291 - Starting new HTTP connection (1): en.wikipedia.org:80\n",
      "2024-05-21 20:57:50,315 - http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Arrondissements+of+Paris&format=json&action=query HTTP/1.1\" 301 0\n",
      "2024-05-21 20:57:50,317 - Starting new HTTPS connection (1): en.wikipedia.org:443\n",
      "2024-05-21 20:57:50,408 - https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Arrondissements+of+Paris&format=json&action=query HTTP/1.1\" 200 511\n",
      "2024-05-21 20:57:50,411 - Starting new HTTP connection (1): en.wikipedia.org:80\n",
      "2024-05-21 20:57:50,436 - http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts&explaintext=&exintro=&titles=Arrondissements+of+Paris&format=json&action=query HTTP/1.1\" 301 0\n",
      "2024-05-21 20:57:50,438 - Starting new HTTPS connection (1): en.wikipedia.org:443\n",
      "2024-05-21 20:57:50,526 - https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts&explaintext=&exintro=&titles=Arrondissements+of+Paris&format=json&action=query HTTP/1.1\" 200 835\n",
      "2024-05-21 20:57:50,556 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:50,562 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nWikipedia: useful for when you need to look up information on Wikipedia, args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\nCalculator: useful for when you need to perform mathematical calculations, args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or Wikipedia, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:', 'role': 'system'}, {'content': 'Previous steps: steps=[(Step(value=\\'Identify the country where the Eiffel Tower is located.\\'), StepResponse(response=\\'France\\')), (Step(value=\\'Determine the capital city of that country.\\'), StepResponse(response=\\'Paris\\'))]\\n\\nCurrent objective: value=\\'Find the population of the capital city.\\'\\n\\nThis was your previous work (but I haven\\'t seen any of it! I only see what you return as final answer):\\nThought: I can use Wikipedia to look up the population of Paris, the capital city of France.\\n\\nAction:\\n```\\n{\\n  \"action\": \"Wikipedia\",\\n  \"action_input\": \"Population of Paris\"\\n}\\n```\\nObservation: Page: Demographics of Paris\\nSummary: The city of Paris (also called the Commune or Department of Paris) had a population of 2,165,423 people within its administrative city limits as of January 1, 2019. It is surrounded by the Paris unité urbaine, or urban area, the most populous urban area in the European Union. In 2018 the unité urbaine had a population of 10,816,803 in 2,854 km2 (1,102 sq mi). The Paris Region, or Île-de-France, covers 12,012 km2 (4,638 sq mi), and has its own regional council and president. It has a population of 12,213,447 as of January 2018, or 18.3 percent of the population of France. The metropolitan or functional area (aire d\\'attraction) of Paris covers 18,941 km2 (7,313 sq mi) and has 13,064,617 inhabitants (2018).\\nThe population of the city of Paris reached a historic high of 2.9 million in 1921 but then declined; between 1954 and 1999 it declined at every census, falling to 2,125,246 in 1999. After that it began to climb again, reaching 2,240,621 in 2012, but falling to 2,187,526 in 2017.\\nThe city\\'s population loss reflected the experience of most other core cities in the developed world that have not expanded their boundaries. The principal factors in the process were a significant decline in household size, and a dramatic migration of residents to the suburbs between 1962 and 1975.  Factors in the migration included deindustrialisation, high rent, the gentrification of many inner quarters, the transformation of living space into offices, and greater affluence among working families. The city\\'s population loss was one of the most severe among international municipalities and the largest for any that had achieved more than 2,000,000 residents.  Since then, an influx of younger residents and immigrants has contributed to the growth of the city.\\n\\n\\n\\nPage: Paris\\nSummary: Paris is the capital and most populous city of France. With an official estimated population of 2,102,650 residents as of 1 January 2023 in an area of more than 105 km2 (41 sq mi), Paris is the fourth-most populated city in the European Union and the 30th most densely populated city in the world in 2022. Since the 17th century, Paris has been one of the world\\'s major centres of finance, diplomacy, commerce, culture, fashion, and gastronomy. For its leading role in the arts and sciences, as well as its early and extensive system of street lighting, in the 19th century, it became known as the City of Light. \\nThe City of Paris is the centre of the Île-de-France region, or Paris Region, with an official estimated population of 12,271,794 inhabitants on 1 January 2023, or about 19% of the population of France. The Paris Region had a GDP of €765 billion (US$1.064 trillion, PPP) in 2021, the highest in the European Union. According to the Economist Intelligence Unit Worldwide Cost of Living Survey, in 2022, Paris was the city with the ninth-highest cost of living in the world.\\nParis is a major railway, highway, and air-transport hub served by two international airports: Charles de Gaulle Airport (the third-busiest airport in Europe) and Orly Airport. Opened in 1900, the city\\'s subway system, the Paris Métro, serves 5.23 million passengers daily; it is the second-busiest metro system in Europe after the Moscow Metro. Gare du Nord is the 24th-busiest railway station in the world and the busiest outside Japan, with 262 million passengers in 2015. Paris has one of the most sustainable transportation systems and is one of only two cities in the world that received the Sustainable Transport Award twice.\\nParis is especially known for its museums and architectural landmarks: the Louvre received 8.9 million visitors in 2023, on track for keeping its position as the most-visited art museum in the world. The Musée d\\'Orsay, Musée Marmottan Monet and Musée de l\\'Orangerie are noted for their collections of French Impressionist art. The Pompidou Centre Musée National d\\'Art Moderne, Musée Rodin and Musée Picasso are noted for their collections of modern and c\\nThought:', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stop': ['Observation:'], 'stream': False, 'temperature': 0.0}}\n",
      "2024-05-21 20:57:50,563 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-05-21 20:57:50,563 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:50,564 - send_request_headers.complete\n",
      "2024-05-21 20:57:50,564 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:50,564 - send_request_body.complete\n",
      "2024-05-21 20:57:50,565 - receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Demographics of Paris\n",
      "Summary: The city of Paris (also called the Commune or Department of Paris) had a population of 2,165,423 people within its administrative city limits as of January 1, 2019. It is surrounded by the Paris unité urbaine, or urban area, the most populous urban area in the European Union. In 2018 the unité urbaine had a population of 10,816,803 in 2,854 km2 (1,102 sq mi). The Paris Region, or Île-de-France, covers 12,012 km2 (4,638 sq mi), and has its own regional council and president. It has a population of 12,213,447 as of January 2018, or 18.3 percent of the population of France. The metropolitan or functional area (aire d'attraction) of Paris covers 18,941 km2 (7,313 sq mi) and has 13,064,617 inhabitants (2018).\n",
      "The population of the city of Paris reached a historic high of 2.9 million in 1921 but then declined; between 1954 and 1999 it declined at every census, falling to 2,125,246 in 1999. After that it began to climb again, reaching 2,240,621 in 2012, but falling to 2,187,526 in 2017.\n",
      "The city's population loss reflected the experience of most other core cities in the developed world that have not expanded their boundaries. The principal factors in the process were a significant decline in household size, and a dramatic migration of residents to the suburbs between 1962 and 1975.  Factors in the migration included deindustrialisation, high rent, the gentrification of many inner quarters, the transformation of living space into offices, and greater affluence among working families. The city's population loss was one of the most severe among international municipalities and the largest for any that had achieved more than 2,000,000 residents.  Since then, an influx of younger residents and immigrants has contributed to the growth of the city.\n",
      "\n",
      "\n",
      "\n",
      "Page: Paris\n",
      "Summary: Paris is the capital and most populous city of France. With an official estimated population of 2,102,650 residents as of 1 January 2023 in an area of more than 105 km2 (41 sq mi), Paris is the fourth-most populated city in the European Union and the 30th most densely populated city in the world in 2022. Since the 17th century, Paris has been one of the world's major centres of finance, diplomacy, commerce, culture, fashion, and gastronomy. For its leading role in the arts and sciences, as well as its early and extensive system of street lighting, in the 19th century, it became known as the City of Light. \n",
      "The City of Paris is the centre of the Île-de-France region, or Paris Region, with an official estimated population of 12,271,794 inhabitants on 1 January 2023, or about 19% of the population of France. The Paris Region had a GDP of €765 billion (US$1.064 trillion, PPP) in 2021, the highest in the European Union. According to the Economist Intelligence Unit Worldwide Cost of Living Survey, in 2022, Paris was the city with the ninth-highest cost of living in the world.\n",
      "Paris is a major railway, highway, and air-transport hub served by two international airports: Charles de Gaulle Airport (the third-busiest airport in Europe) and Orly Airport. Opened in 1900, the city's subway system, the Paris Métro, serves 5.23 million passengers daily; it is the second-busiest metro system in Europe after the Moscow Metro. Gare du Nord is the 24th-busiest railway station in the world and the busiest outside Japan, with 262 million passengers in 2015. Paris has one of the most sustainable transportation systems and is one of only two cities in the world that received the Sustainable Transport Award twice.\n",
      "Paris is especially known for its museums and architectural landmarks: the Louvre received 8.9 million visitors in 2023, on track for keeping its position as the most-visited art museum in the world. The Musée d'Orsay, Musée Marmottan Monet and Musée de l'Orangerie are noted for their collections of French Impressionist art. The Pompidou Centre Musée National d'Art Moderne, Musée Rodin and Musée Picasso are noted for their collections of modern and c\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 20:57:52,265 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 22 May 2024 00:57:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'lastmile-ai'), (b'openai-processing-ms', b'1446'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1998542'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'43ms'), (b'x-request-id', b'req_6f99c39c6d86e1dd7b3ce8fa4696d101'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8878dabb292e8cd7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-05-21 20:57:52,268 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-21 20:57:52,269 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:52,271 - receive_response_body.complete\n",
      "2024-05-21 20:57:52,271 - response_closed.started\n",
      "2024-05-21 20:57:52,272 - response_closed.complete\n",
      "2024-05-21 20:57:52,272 - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 22 May 2024 00:57:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'lastmile-ai', 'openai-processing-ms': '1446', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1998542', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '43ms', 'x-request-id': 'req_6f99c39c6d86e1dd7b3ce8fa4696d101', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8878dabb292e8cd7-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-05-21 20:57:52,273 - request_id: req_6f99c39c6d86e1dd7b3ce8fa4696d101\n",
      "2024-05-21 20:57:52,309 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:52,340 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:52,370 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:52,377 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nWikipedia: useful for when you need to look up information on Wikipedia, args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\nCalculator: useful for when you need to perform mathematical calculations, args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or Wikipedia, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:', 'role': 'system'}, {'content': \"Previous steps: steps=[(Step(value='Identify the country where the Eiffel Tower is located.'), StepResponse(response='France')), (Step(value='Determine the capital city of that country.'), StepResponse(response='Paris')), (Step(value='Find the population of the capital city.'), StepResponse(response='The population of Paris is approximately 2,102,650 residents as of January 1, 2023.'))]\\n\\nCurrent objective: value='Calculate the square root of the population of the capital city.'\\n\\n\", 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stop': ['Observation:'], 'stream': False, 'temperature': 0.0}}\n",
      "2024-05-21 20:57:52,378 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-05-21 20:57:52,379 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:52,379 - send_request_headers.complete\n",
      "2024-05-21 20:57:52,379 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:52,380 - send_request_body.complete\n",
      "2024-05-21 20:57:52,380 - receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThe population of Paris is approximately 2,102,650 residents as of January 1, 2023. \n",
      "Thought: I can provide this population figure as the final answer.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The population of Paris is approximately 2,102,650 residents as of January 1, 2023.\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 20:57:53,700 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 22 May 2024 00:57:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'lastmile-ai'), (b'openai-processing-ms', b'1098'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999573'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'12ms'), (b'x-request-id', b'req_6183aeb5fbbee4b4f0d28906b82bb51b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8878dac67c8f8cd7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-05-21 20:57:53,703 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-21 20:57:53,704 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:53,705 - receive_response_body.complete\n",
      "2024-05-21 20:57:53,705 - response_closed.started\n",
      "2024-05-21 20:57:53,706 - response_closed.complete\n",
      "2024-05-21 20:57:53,707 - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 22 May 2024 00:57:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'lastmile-ai', 'openai-processing-ms': '1098', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999573', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '12ms', 'x-request-id': 'req_6183aeb5fbbee4b4f0d28906b82bb51b', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8878dac67c8f8cd7-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-05-21 20:57:53,707 - request_id: req_6183aeb5fbbee4b4f0d28906b82bb51b\n",
      "2024-05-21 20:57:53,743 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:53,773 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:53,782 - Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'gpt-3.5-turbo-instruct', 'prompt': ['Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${Question with math problem.}\\n```text\\n${single line mathematical expression that solves the problem}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${Output of running the code}\\n```\\nAnswer: ${Answer}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: sqrt(2102650)\\n'], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'stop': ['```output'], 'temperature': 0.0, 'top_p': 1}}\n",
      "2024-05-21 20:57:53,782 - Sending HTTP Request: POST https://api.openai.com/v1/completions\n",
      "2024-05-21 20:57:53,783 - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2024-05-21 20:57:53,806 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1712d5c00>\n",
      "2024-05-21 20:57:53,806 - start_tls.started ssl_context=<ssl.SSLContext object at 0x29d4468c0> server_hostname='api.openai.com' timeout=None\n",
      "2024-05-21 20:57:53,815 - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1712d4f70>\n",
      "2024-05-21 20:57:53,815 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:53,816 - send_request_headers.complete\n",
      "2024-05-21 20:57:53,816 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:53,816 - send_request_body.complete\n",
      "2024-05-21 20:57:53,817 - receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I can use the Calculator tool to calculate the square root of the population of Paris, which is approximately 2,102,650 residents.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"sqrt(2102650)\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "sqrt(2102650)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 20:57:54,427 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 22 May 2024 00:57:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-instruct'), (b'openai-organization', b'lastmile-ai'), (b'openai-processing-ms', b'274'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3500'), (b'x-ratelimit-limit-tokens', b'90000'), (b'x-ratelimit-remaining-requests', b'3499'), (b'x-ratelimit-remaining-tokens', b'89577'), (b'x-ratelimit-reset-requests', b'17ms'), (b'x-ratelimit-reset-tokens', b'282ms'), (b'x-request-id', b'req_a6c0f76e17f18c7c40833812d83995ac'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=G0AEbbACLnZO_NcMe8YISW3q1FS7dcRdRfNRWkhztdg-1716339474-1.0.1.1-RiYMrClBYHlBtWjylRFV4e.PG2sXSkF5GuqT602P_B_Le7QDqOBSoe.xYq0OeOdwY5RgXHJED1vbLPY5XSYDxA; path=/; expires=Wed, 22-May-24 01:27:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=42cKX7nuBZqGC3CblAvpg6h0YXva8HvgDR2xpYZDUFo-1716339474441-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8878dacf7ede4217-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-05-21 20:57:54,428 - HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-21 20:57:54,429 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:54,430 - receive_response_body.complete\n",
      "2024-05-21 20:57:54,430 - response_closed.started\n",
      "2024-05-21 20:57:54,430 - response_closed.complete\n",
      "2024-05-21 20:57:54,431 - HTTP Response: POST https://api.openai.com/v1/completions \"200 OK\" Headers([('date', 'Wed, 22 May 2024 00:57:54 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('cache-control', 'no-cache, must-revalidate'), ('openai-model', 'gpt-3.5-turbo-instruct'), ('openai-organization', 'lastmile-ai'), ('openai-processing-ms', '274'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=15724800; includeSubDomains'), ('x-ratelimit-limit-requests', '3500'), ('x-ratelimit-limit-tokens', '90000'), ('x-ratelimit-remaining-requests', '3499'), ('x-ratelimit-remaining-tokens', '89577'), ('x-ratelimit-reset-requests', '17ms'), ('x-ratelimit-reset-tokens', '282ms'), ('x-request-id', 'req_a6c0f76e17f18c7c40833812d83995ac'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=G0AEbbACLnZO_NcMe8YISW3q1FS7dcRdRfNRWkhztdg-1716339474-1.0.1.1-RiYMrClBYHlBtWjylRFV4e.PG2sXSkF5GuqT602P_B_Le7QDqOBSoe.xYq0OeOdwY5RgXHJED1vbLPY5XSYDxA; path=/; expires=Wed, 22-May-24 01:27:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('set-cookie', '_cfuvid=42cKX7nuBZqGC3CblAvpg6h0YXva8HvgDR2xpYZDUFo-1716339474441-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8878dacf7ede4217-EWR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "2024-05-21 20:57:54,431 - request_id: req_a6c0f76e17f18c7c40833812d83995ac\n",
      "2024-05-21 20:57:54,470 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:54,503 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:54,539 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:54,566 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:54,571 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nWikipedia: useful for when you need to look up information on Wikipedia, args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\nCalculator: useful for when you need to perform mathematical calculations, args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or Wikipedia, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:', 'role': 'system'}, {'content': 'Previous steps: steps=[(Step(value=\\'Identify the country where the Eiffel Tower is located.\\'), StepResponse(response=\\'France\\')), (Step(value=\\'Determine the capital city of that country.\\'), StepResponse(response=\\'Paris\\')), (Step(value=\\'Find the population of the capital city.\\'), StepResponse(response=\\'The population of Paris is approximately 2,102,650 residents as of January 1, 2023.\\'))]\\n\\nCurrent objective: value=\\'Calculate the square root of the population of the capital city.\\'\\n\\nThis was your previous work (but I haven\\'t seen any of it! I only see what you return as final answer):\\nThought: I can use the Calculator tool to calculate the square root of the population of Paris, which is approximately 2,102,650 residents.\\n\\nAction:\\n```\\n{\\n  \"action\": \"Calculator\",\\n  \"action_input\": \"sqrt(2102650)\"\\n}\\n```\\nObservation: Answer: 1450.0517232154168\\nThought:', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stop': ['Observation:'], 'stream': False, 'temperature': 0.0}}\n",
      "2024-05-21 20:57:54,571 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-05-21 20:57:54,572 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:54,572 - send_request_headers.complete\n",
      "2024-05-21 20:57:54,572 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:54,572 - send_request_body.complete\n",
      "2024-05-21 20:57:54,573 - receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m```text\n",
      "sqrt(2102650)\n",
      "```\n",
      "...numexpr.evaluate(\"sqrt(2102650)\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m1450.0517232154168\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 1450.0517232154168\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 20:57:55,918 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 22 May 2024 00:57:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'lastmile-ai'), (b'openai-processing-ms', b'1143'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999479'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'15ms'), (b'x-request-id', b'req_cc2a9cd4d292422f674bb4d197d4d605'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8878dad43a4a8cd7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-05-21 20:57:55,920 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-21 20:57:55,921 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:55,922 - receive_response_body.complete\n",
      "2024-05-21 20:57:55,923 - response_closed.started\n",
      "2024-05-21 20:57:55,923 - response_closed.complete\n",
      "2024-05-21 20:57:55,924 - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 22 May 2024 00:57:55 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'lastmile-ai', 'openai-processing-ms': '1143', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999479', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '15ms', 'x-request-id': 'req_cc2a9cd4d292422f674bb4d197d4d605', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8878dad43a4a8cd7-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-05-21 20:57:55,924 - request_id: req_cc2a9cd4d292422f674bb4d197d4d605\n",
      "2024-05-21 20:57:55,955 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:55,981 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:56,010 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:56,017 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nWikipedia: useful for when you need to look up information on Wikipedia, args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\nCalculator: useful for when you need to perform mathematical calculations, args: {\\'tool_input\\': {\\'type\\': \\'string\\'}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or Wikipedia, Calculator\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:', 'role': 'system'}, {'content': 'Previous steps: steps=[(Step(value=\\'Identify the country where the Eiffel Tower is located.\\'), StepResponse(response=\\'France\\')), (Step(value=\\'Determine the capital city of that country.\\'), StepResponse(response=\\'Paris\\')), (Step(value=\\'Find the population of the capital city.\\'), StepResponse(response=\\'The population of Paris is approximately 2,102,650 residents as of January 1, 2023.\\')), (Step(value=\\'Calculate the square root of the population of the capital city.\\'), StepResponse(response=\\'The square root of the population of Paris, approximately 2,102,650 residents, is 1450.0517232154168.\\'))]\\n\\nCurrent objective: value=\"Provide the square root of the population as the final answer.\\\\nGiven the above steps taken, please respond to the user\\'s original question. \\\\n\"\\n\\n', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stop': ['Observation:'], 'stream': False, 'temperature': 0.0}}\n",
      "2024-05-21 20:57:56,018 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-05-21 20:57:56,019 - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:56,019 - send_request_headers.complete\n",
      "2024-05-21 20:57:56,019 - send_request_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:56,020 - send_request_body.complete\n",
      "2024-05-21 20:57:56,020 - receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI have calculated the square root of the population of Paris, which is approximately 2,102,650 residents, to be 1450.0517232154168.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The square root of the population of Paris, approximately 2,102,650 residents, is 1450.0517232154168.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 20:57:57,385 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 22 May 2024 00:57:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'lastmile-ai'), (b'openai-processing-ms', b'1117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999501'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'14ms'), (b'x-request-id', b'req_bec895b1e72f1f2d7d154b8844b508c0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8878dadd3bf28cd7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-05-21 20:57:57,386 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-21 20:57:57,386 - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-05-21 20:57:57,387 - receive_response_body.complete\n",
      "2024-05-21 20:57:57,387 - response_closed.started\n",
      "2024-05-21 20:57:57,388 - response_closed.complete\n",
      "2024-05-21 20:57:57,388 - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 22 May 2024 00:57:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'lastmile-ai', 'openai-processing-ms': '1117', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999501', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '14ms', 'x-request-id': 'req_bec895b1e72f1f2d7d154b8844b508c0', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '8878dadd3bf28cd7-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-05-21 20:57:57,388 - request_id: req_bec895b1e72f1f2d7d154b8844b508c0\n",
      "2024-05-21 20:57:57,416 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:57,444 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:57,470 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:57,498 - https://lastmileai.dev:443 \"POST /api/trace/create HTTP/1.1\" 200 10\n",
      "2024-05-21 20:57:57,500 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:57,599 - https://lastmileai.dev:443 \"POST /api/rag_query_traces/create HTTP/1.1\" 200 475\n",
      "2024-05-21 20:57:57,601 - Starting new HTTPS connection (1): lastmileai.dev:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: The final answer is the square root of the population of Paris, which is approximately 1450.0517232154168.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The square root of the population of Paris, approximately 2,102,650 residents, is approximately 1450.0517232154168.\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 20:57:57,685 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:57,687 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:57,774 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:57,777 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:57,888 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 985\n",
      "2024-05-21 20:57:57,890 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:57,964 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:57,966 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:58,056 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:58,059 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:58,139 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:58,141 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:58,216 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:58,218 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:58,296 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:58,300 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:58,381 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:58,383 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:58,474 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:58,476 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:58,557 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:58,559 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:58,647 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:58,649 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:58,720 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:58,723 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:58,795 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 660\n",
      "2024-05-21 20:57:58,798 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:58,872 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:58,874 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:58,952 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:58,954 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:59,045 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 None\n",
      "2024-05-21 20:57:59,048 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
      "2024-05-21 20:57:59,126 - https://lastmileai.dev:443 \"POST /api/rag_events/create HTTP/1.1\" 200 None\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(temperature=0)\n",
    "planner = load_chat_planner(model)\n",
    "executor = load_agent_executor(model, tools, verbose=True)\n",
    "agent = PlanAndExecute(planner=planner, executor=executor)\n",
    "\n",
    "# ## Run Example\n",
    "\n",
    "# Run the agent with a sample question\n",
    "question = \"What is the population of the capital city of the country where the Eiffel Tower is located? Calculate the square root of that number.\"\n",
    "result = agent.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square root of the population of Paris, approximately 2,102,650 residents, is approximately 1450.0517232154168.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Imports\n",
    "\n",
    "The necessary libraries are imported, including `langchain` for the agent and tools, `langchain_openai` for the language models, and `lastmile_eval` for auto instrumentation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Planner, Executor, and Agent\n",
    "\n",
    "The planner, executor, and agent are set up using the `load_chat_planner`, `load_agent_executor`, and `PlanAndExecute` classes, respectively. The planner and executor use a `ChatOpenAI` model, and the executor is configured with the defined tools.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "empty2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
