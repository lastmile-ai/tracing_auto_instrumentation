{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "3e67f200",
            "metadata": {},
            "source": [
                "# OpenAI Streaming - Traced With LastMile\n",
                "\n",
                "Four use cases:\n",
                "\n",
                "1. Text - Non-streaming\n",
                "2. [this one] Text - Streaming\n",
                "3. Tool Calls - Non-streaming\n",
                "4. Tool Calls - Streaming"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "80e71f33",
            "metadata": {
                "pycharm": {
                    "is_executing": true
                }
            },
            "outputs": [],
            "source": [
                "# !pip install scipy --quiet\n",
                "# !pip install tenacity --quiet\n",
                "# !pip install tiktoken --quiet\n",
                "# !pip install termcolor --quiet\n",
                "# !pip install openai --quiet\n",
                "# !pip install \"tracing-auto-instrumentation[openai]\"\n",
                "\n",
                "# Create ~/.env file with this line: OPENAI_API_KEY=<your key here>\n",
                "# You can get your key from https://platform.openai.com/api-keys \n",
                "import openai\n",
                "import dotenv\n",
                "import os\n",
                "dotenv.load_dotenv()\n",
                "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "4abf2967",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/homebrew/Caskroom/miniconda/base/envs/eval/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n",
                        "2024-05-29 19:06:59,241 - Starting new HTTPS connection (1): lastmileai.dev:443\n",
                        "2024-05-29 19:06:59,323 - https://lastmileai.dev:443 \"GET /api/evaluation_projects/list?name=OpenAI+Text+Calling+w.+Streaming HTTP/1.1\" 200 367\n",
                        "2024-05-29 19:06:59,325 - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
                        "2024-05-29 19:06:59,326 - load_verify_locations cafile='/opt/homebrew/Caskroom/miniconda/base/envs/eval/lib/python3.12/site-packages/certifi/cacert.pem'\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "get wrapping...\n",
                        "enter 1\n",
                        "inside openai v1 wrapper\n",
                        "chatv1 wrapper initializing...\n",
                        "chat.completions=<openai.resources.chat.completions.Completions object at 0x1519a0aa0>\n",
                        "chatv1 wrapper regular completions\n",
                        "inside regular embedding wrapper\n"
                    ]
                }
            ],
            "source": [
                "import openai\n",
                "\n",
                "from lastmile_eval.rag.debugger.api.tracing import LastMileTracer\n",
                "\n",
                "from tracing_auto_instrumentation.openai import openai as openai_tracing\n",
                "from lastmile_eval.rag.debugger.tracing.sdk import get_lastmile_tracer\n",
                "\n",
                "tracer: LastMileTracer = get_lastmile_tracer(\n",
                "    tracer_name=\"OpenAI Text Calling w. Streaming\",\n",
                ")\n",
                "openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
                "client = openai_tracing.wrap(openai_client, tracer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "4276d4b0",
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_my_existing_openai_app(user_message: str, stream: bool = True):\n",
                "    completion_params = {\n",
                "        \"model\": \"gpt-3.5-turbo\",\n",
                "        \"top_p\": 1,\n",
                "        \"max_tokens\": 3000,\n",
                "        \"temperature\": 1,\n",
                "        \"stream\": stream,\n",
                "        \"messages\": [\n",
                "            {\n",
                "                \"content\": user_message,\n",
                "                \"role\": \"user\",\n",
                "            }\n",
                "        ],\n",
                "    }\n",
                "    import inspect\n",
                "    print(inspect.getsource(client.chat.completions.create))\n",
                "\n",
                "    response = client.chat.completions.create(**completion_params)\n",
                "    print(\"Chat Completion Response: \")\n",
                "    if stream:\n",
                "        for chunk in response:\n",
                "            print(f\"{chunk=}\")\n",
                "    else:\n",
                "        print(f\"{response=}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "4a491c03",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "True\n"
                    ]
                }
            ],
            "source": [
                "print(hasattr(openai_client, \"chat\") and hasattr(openai_client.chat, \"completions\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "9aa6f3f6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "    def create(self, *args, **kwargs):\n",
                        "        print(\"V1, about to enter create function\")\n",
                        "        return ChatCompletionWrapper(\n",
                        "            self.__completions.create, None, self.tracer\n",
                        "        ).create(*args, **kwargs)\n",
                        "\n",
                        "V1, about to enter create function\n",
                        "completion wrapper is initializing...\n",
                        "Chat Completion Response: \n",
                        "response=<generator object ChatCompletionWrapper.create at 0x151789460>\n"
                    ]
                }
            ],
            "source": [
                "# Run your code as usual\n",
                "stream = False\n",
                "run_my_existing_openai_app(\"Tell me a joke about apples\", stream=stream)\n",
                "\n",
                "import inspect \n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
